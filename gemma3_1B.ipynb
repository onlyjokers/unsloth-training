{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7e62a6",
   "metadata": {},
   "source": [
    "### 引用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858b9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 03-21 16:41:55 [__init__.py:256] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.3.17: Fast Gemma3 patching. Transformers: 4.50.0.dev0. vLLM: 0.8.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti SUPER. Num GPUs = 1. Max memory: 15.992 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024 # 模型的最大序列长度，默认是1024\n",
    "lora_rank = 8 # LoRA的秩，越大越好，但会消耗更多内存 #8\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"./models/gemma-3-1b-it\", #\"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length = max_seq_length, # 可以选择任意长度以支持长上下文！\n",
    "    load_in_4bit = False,  # 4位量化以减少内存使用\n",
    "    load_in_8bit = False, # 精度更高，但使用2倍内存\n",
    "    full_finetuning = False, # 现在我们支持完全微调了！\n",
    "    # gpu_memory_utilization = 0.85, # GPU内存使用率，如果出现OOM可以降低此值\n",
    "    # token = \"hf_...\", # 使用受限模型时需要提供token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e380ab",
   "metadata": {},
   "source": [
    "### 加载 Lora 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127dd5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # 仅处理文本层或者模型没有视觉层时关闭！\n",
    "    finetune_language_layers   = True,  # 应该保持开启！\n",
    "    finetune_attention_modules = True,  # 注意力机制对GRPO有好处\n",
    "    finetune_mlp_modules       = True,  # 应该始终保持开启！\n",
    "\n",
    "    r = lora_rank,           # 更大 = 更高的精度，但可能过拟合\n",
    "    lora_alpha = lora_rank,  # 建议alpha至少等于r\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407, # 使用同一个随机数种子\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ced53c",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b997c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 7473\n",
      "})\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 2008\n",
      "})\n",
      "别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长\n",
      "<think>好的，我现在需要处理用户提供的这个查询：“别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长”。首先，我需要理解用户的意思以及背后的情感。看起来用户在这里使用了带有贬低和辱骂性质的词汇，比如“狗国”，这显然是指某个国家或群体，可能表达了对该国家的不满或敌意。\n",
      "\n",
      "接下来，我要分析用户的需求。用户可能希望我回应或同意他们的观点，或者提供某种支持他们情绪的内容。然而，根据规则，我的回应必须遵守中国法律法规，保持中立和客观，并且不能含有任何攻击性或不当言论。因此，我不能支持或强化用户的负面情绪，也不能使用类似的侮辱性语言。\n",
      "\n",
      "然后，我需要考虑如何以适当的方式回应用户。用户可能感到愤怒或不满，我的回应应该既保持礼貌，又引导他们以更建设性的方式表达意见。根据示例响应，正确的做法是提醒用户文明交流，强调不鼓励使用不尊重或攻击性语言，并建议基于相互尊重的对话。\n",
      "\n",
      "此外，我要确保回应中没有违反任何规定，比如不涉及政治敏感话题，不侮辱任何国家或群体。同时，要避免提供任何可能被误解为支持用户观点的内容。需要保持中立，既不赞同也不反对，而是转向促进积极对话的方向。\n",
      "\n",
      "另外，要注意用户可能的深层需求。他们可能希望被倾听或得到情感支持，但表达方式不当。在这种情况下，引导他们用更合适的方式表达不满才是关键，而不是直接回应他们的情绪。\n",
      "\n",
      "最后，总结应对策略：礼貌地提醒用户注意语言文明，说明不鼓励攻击性言论，提倡相互尊重的交流方式。保持中立，避免任何可能引起争议或冲突的回应，确保符合规定和法律法规。\n",
      "</think>\n",
      "\n",
      "我们始终主张不同国家和文化之间应相互尊重、平等交流。任何问题都应本着客观理性的态度进行讨论,用建设性对话增进理解。中华文化历来讲究\"和为贵\",我们相信只有摈弃偏见、以心相交,才能实现不同文明和谐共处。\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# json 格式\n",
    "dataset2 = load_dataset(\"json\", data_files=\"./datasets/ruozhiba_R1/alpaca_output_main.jsonl\", split='train')\n",
    "\n",
    "# parquet 格式\n",
    "dataset = load_dataset(\"parquet\", data_files=\"./datasets/gsm8k/main/train-00000-of-00001.parquet\", split='train')\n",
    "\n",
    "# 查看数据情况\n",
    "print(dataset)\n",
    "print(dataset[0][\"question\"])\n",
    "print(dataset[0][\"answer\"])\n",
    "\n",
    "print(dataset2)\n",
    "print(dataset2[0][\"instruction\"])\n",
    "print(dataset2[0][\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc70941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答总是以####开头，对回答数据做抽取，为后续的数据集清理做准备。\n",
    "def extract_hash_answer(text):\n",
    "    if \"####\" not in text: return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "extract_hash_answer(dataset[0][\"answer\"])\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    从文本中提取</think>标签之后的所有内容\n",
    "    \n",
    "    参数:\n",
    "        text: 包含</think>标签的文本\n",
    "        \n",
    "    返回:\n",
    "        str: </think>标签之后的所有内容，去除首尾空格\n",
    "    \"\"\"\n",
    "    if \"</think>\" not in text:\n",
    "        return text.strip()\n",
    "    answer = text.split(\"</think>\")[-1]  # 提取</think>标签后的所有内容\n",
    "    return answer.strip()  # 去除首尾空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3e53ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置系统提示此\n",
    "reasoning_start = \"<start_working_out>\"\n",
    "reasoning_end   = \"<end_working_out>\"\n",
    "solution_start = \"<SOLUTION>\"\n",
    "solution_end = \"</SOLUTION>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"你被给定了一个问题，考虑问题并提供你给出的答案。\n",
    "请将思考过程放在 {reasoning_start} 和 {reasoning_end} 之间。\n",
    "然后，请在 {solution_start} 和 {solution_end} 之间提供你的答案。\"\"\"\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facc11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2 size 2008\n",
      "Filtered dataset2 from original size to 1979 valid examples\n",
      "Combined dataset size: 9452\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# 获取数据集所有列名\n",
    "original_columns = dataset.column_names\n",
    "\n",
    "# 替换而非添加\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\n",
    "        \"prompt\" : [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": x[\"question\"]},\n",
    "        ],\n",
    "        \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "    },\n",
    "    remove_columns=original_columns  # 移除所有原始列\n",
    ")\n",
    "\n",
    "print(f\"dataset2 size {len(dataset2)}\")\n",
    "# 定义函数检查回答是否为空或只有空格/句号\n",
    "def has_valid_content(output_text):\n",
    "    \"\"\"检查</think>标签后的内容是否有效（不是空的、只有空格或只有句号）\"\"\"\n",
    "    if \"</think>\" not in output_text:\n",
    "        return False  # 没有</think>标签，保留\n",
    "    \n",
    "    content_after_tag = extract_xml_answer(output_text)\n",
    "    # 检查提取的内容是否为空、只有空格或只有句号\n",
    "    if not content_after_tag or content_after_tag.isspace() or content_after_tag == \".\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# 过滤掉answer内容无效的条目\n",
    "valid_indices = [i for i, example in enumerate(dataset2) if 'output' in example and has_valid_content(example['output'])]\n",
    "dataset2 = dataset2.select(valid_indices)\n",
    "print(f\"Filtered dataset2 from original size to {len(dataset2)} valid examples\")\n",
    "\n",
    "\n",
    "original_columns2 = dataset2.column_names\n",
    "dataset2 = dataset2.map(\n",
    "    lambda x: {\n",
    "        \"prompt\" : [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": x[\"instruction\"] if 'instruction' in x else x.get('input', '')},\n",
    "        ],\n",
    "        \"answer\": extract_xml_answer(x[\"output\"]),\n",
    "    },\n",
    "    remove_columns=original_columns2\n",
    ")\n",
    "\n",
    "# 合并两个数据集，并打乱\n",
    "dataset = concatenate_datasets([dataset, dataset2])\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "print(f\"Combined dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaf472",
   "metadata": {},
   "source": [
    "### 定义奖励函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ab0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 定义正则表达式，用来判断模型的输出是否符合格式要求\n",
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\\\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\\\n",
    "    rf\"{solution_start}(.+?){solution_end}\"\\\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ff8dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 71), match='<start_working_out>Let me think!<end_working_out>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_format.search(\n",
    "    \"<start_working_out>Let me think!<end_working_out>\"\\\n",
    "    \"<SOLUTION>2</SOLUTION>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1c793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式匹配函数\n",
    "def match_format_exactly(completions, **kwargs):\n",
    "    \"\"\"格式判断函数，严格判断格式是否匹配\n",
    "\n",
    "    Args:\n",
    "        completions (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: Number 0 ｜ 3\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Match if format is seen exactly!\n",
    "        if match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13513da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_approximately(completions, **kwargs):\n",
    "    \"\"\"弱格式判断奖励，即使没有严格对应，也可以根据使用的标签数量来做出相应的奖励\n",
    "\n",
    "    Args:\n",
    "        completions (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: Number\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # 数一数看到多少个关键词——如果太多，我们会惩罚你！\n",
    "        # 如果我们看到1，那么加一些积分！如果更多了，那么就应当扣除一些分\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end)   == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start)  == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end)    == 1 else -0.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e10a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"通过比较提取的答案与参考答案来评估模型响应。\n",
    "    \n",
    "    该函数从结构化模型输出中提取答案并与参考答案进行比较，根据匹配质量分配分数：\n",
    "    - 完全匹配：3.0分\n",
    "    - 去除空格后匹配：1.5分\n",
    "    - 数值答案在正确值10%范围内：0.5分\n",
    "    - 数值答案在正确值20%范围内：0.25分\n",
    "    - 错误答案：-0.5或-1.0分\n",
    "    \n",
    "    参数：\n",
    "        prompts (list)：提供给模型的对话提示列表\n",
    "        completions (list)：需要评估的模型生成的回答\n",
    "        answer (list)：用于比较的参考答案\n",
    "        **kwargs：额外参数\n",
    "        \n",
    "    返回：\n",
    "        list：基于答案正确性的每个回答的得分\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_format.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # 如果完全一致，就给出 3 分 \n",
    "        if guess == true_answer:\n",
    "            score += 3.0\n",
    "        # 如果结果正确，但是有空格，就给1.5分\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 1.5\n",
    "        else:\n",
    "            # 如果答案接近比率，我们也会奖励它！\n",
    "            # 即，如果答案在某个范围内，奖励它！\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if   ratio >= 0.9 and ratio <= 1.1: score += 0.5\n",
    "                elif ratio >= 0.8 and ratio <= 1.2: score += 0.25\n",
    "                else: score -= 1.0 # Penalize wrong answers\n",
    "            except:\n",
    "                # 如果直接异常了，就抛出错误\n",
    "                score -= 0.5 # Penalize\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb3d61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.34']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于数学问题，先给数字部分抽取出来\n",
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "match_numbers.findall(\"<SOLUTION>  0.34  </SOLUTION>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9bc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numbers(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"使用正则表达式从模型输出中提取数字答案并进行评分。\n",
    "    \n",
    "    该函数从模型响应中提取数字，并与参考答案进行数值比较。\n",
    "    如果提取的数字与正确答案完全匹配，将获得1.5分，否则为0分。\n",
    "    \n",
    "    参数：\n",
    "        prompts (list)：提供给模型的对话提示列表\n",
    "        completions (list)：需要评估的模型生成的回答\n",
    "        answer (list)：用于比较的参考答案数值\n",
    "        **kwargs：额外参数\n",
    "        \n",
    "    返回：\n",
    "        list：基于数值匹配的评分列表\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_numbers.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    print('*'*20, f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            guess       = float(guess.strip())\n",
    "            scores.append(1.5 if guess == true_answer else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0730a",
   "metadata": {},
   "source": [
    "### 训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bbc15bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "max_prompt_length = 256\n",
    "\n",
    "# 使用 GRPO 训练器，并构造训练器\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    beta = 0.0, # 设置为 0 以禁用 KL 散度惩罚 # defaults to 0.04\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # 增加到4，以便更顺滑地训练 #1\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 1000, # 训练步数\n",
    "    save_steps = 250, # 每50步保存一次\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs_gemma3_1b_it_2\", # 输出目录\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10ffba",
   "metadata": {},
   "source": [
    "开始训练。期望在训练中，看到reward列的数值增长！\n",
    "\n",
    "有可能在开始的100步都没有奖励，你可能需要等待150-200步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b07040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 9,452 | Num Epochs = 1 | Total steps = 1,000\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 6,522,880/1,006,408,832 (0.65% trained)\n"
     ]
    }
   ],
   "source": [
    "# 创建训练器，并且使用上面给出的 reward function\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        match_format_exactly,\n",
    "        match_format_approximately,\n",
    "        check_answer,\n",
    "        check_numbers,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95da640",
   "metadata": {},
   "source": [
    "### 模型测试\n",
    "#### 默认模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b37c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[1;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the sqrt of 101?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m      7\u001b[0m     messages,\n\u001b[1;32m      8\u001b[0m     add_generation_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Must add for generation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     tokenize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextStreamer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'system_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": \"What is the sqrt of 101?\"},\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    tokenize = False,\n",
    ")\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 64, # Increase for longer outputs!\n",
    "    # Recommended Gemma-3 settings!\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833dc17",
   "metadata": {},
   "source": [
    "#### 保存 Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"gemma-3\")  # Local saving\n",
    "tokenizer.save_pretrained(\"gemma-3\")\n",
    "# model.push_to_hub(\"HF_ACCOUNT/gemma-3\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"HF_ACCOUNT/gemma-3\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # Change to True to save finetune!\n",
    "    model.save_pretrained_merged(\"gemma-3-finetune\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a0885",
   "metadata": {},
   "source": [
    "### 保存为完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False: # Change to True to upload finetune\n",
    "#     model.push_to_hub_merged(\n",
    "#         \"HF_ACCOUNT/gemma-3-finetune\", tokenizer,\n",
    "#         token = \"hf_...\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为 GGUF 格式\n",
    "# if False:\n",
    "#     model.save_pretrained_gguf(\n",
    "#         \"gemma-3-finetune\",\n",
    "#         quantization_type = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a89623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False: # Change to True to upload GGUF\n",
    "#     model.push_to_hub_gguf(\n",
    "#         \"gemma-3-finetune\",\n",
    "#         quantization_type = \"Q8_0\", # Only Q8_0, BF16, F16 supported\n",
    "#         repo_id = \"HF_ACCOUNT/gemma-finetune-gguf\",\n",
    "#         token = \"hf_...\",\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
