{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7e62a6",
   "metadata": {},
   "source": [
    "### åŠ è½½\n",
    "#### åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858b9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:05<00:00, 31.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024 # æ¨¡å‹çš„æœ€å¤§åºåˆ—é•¿åº¦ï¼Œé»˜è®¤æ˜¯1024\n",
    "lora_rank = 8 # LoRAçš„ç§©ï¼Œè¶Šå¤§è¶Šå¥½ï¼Œä½†ä¼šæ¶ˆè€—æ›´å¤šå†…å­˜ #8\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"./models/BlenderLLM\", #\"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length = max_seq_length, # å¯ä»¥é€‰æ‹©ä»»æ„é•¿åº¦ä»¥æ”¯æŒé•¿ä¸Šä¸‹æ–‡ï¼\n",
    "    load_in_4bit = True,  # 4ä½é‡åŒ–ä»¥å‡å°‘å†…å­˜ä½¿ç”¨\n",
    "    load_in_8bit = False, # ç²¾åº¦æ›´é«˜ï¼Œä½†ä½¿ç”¨2å€å†…å­˜\n",
    "    full_finetuning = False, # å®Œå…¨å¾®è°ƒ\n",
    "    # gpu_memory_utilization = 0.85, # GPUå†…å­˜ä½¿ç”¨ç‡ï¼Œå¦‚æœå‡ºç°OOMå¯ä»¥é™ä½æ­¤å€¼\n",
    "    # token = \"hf_...\", # ä½¿ç”¨å—é™æ¨¡å‹æ—¶éœ€è¦æä¾›token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e380ab",
   "metadata": {},
   "source": [
    "#### åŠ è½½ Lora è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127dd5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # ä»…å¤„ç†æ–‡æœ¬å±‚æˆ–è€…æ¨¡å‹æ²¡æœ‰è§†è§‰å±‚æ—¶å…³é—­\n",
    "    finetune_language_layers   = True,  # åº”è¯¥ä¿æŒå¼€å¯ï¼\n",
    "    finetune_attention_modules = True,  # æ³¨æ„åŠ›æœºåˆ¶å¯¹GRPOæœ‰å¥½å¤„\n",
    "    finetune_mlp_modules       = True,  # åº”è¯¥å§‹ç»ˆä¿æŒå¼€å¯ï¼\n",
    "\n",
    "    r = lora_rank,           # æ›´å¤§ = æ›´é«˜çš„ç²¾åº¦ï¼Œä½†å¯èƒ½è¿‡æ‹Ÿåˆ\n",
    "    lora_alpha = lora_rank,  # å»ºè®®alphaè‡³å°‘ç­‰äºr\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407, # ä½¿ç”¨åŒä¸€ä¸ªéšæœºæ•°ç§å­\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ced53c",
   "metadata": {},
   "source": [
    "#### åŠ è½½ã€æ„é€ æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b997c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 7473\n",
      "})\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "\n",
      "\n",
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 2008\n",
      "})\n",
      "åˆ«æ‹¿æŸä¸ªç‹—å›½å¤ªå½“å¹²ç²® åˆ«è‡ªä»¥ä¸ºæ˜¯ ç‹—å›½äººå¤š ç–¯ç‹—å£«æ°”é•¿\n",
      "<think>å¥½çš„ï¼Œæˆ‘ç°åœ¨éœ€è¦å¤„ç†ç”¨æˆ·æä¾›çš„è¿™ä¸ªæŸ¥è¯¢ï¼šâ€œåˆ«æ‹¿æŸä¸ªç‹—å›½å¤ªå½“å¹²ç²® åˆ«è‡ªä»¥ä¸ºæ˜¯ ç‹—å›½äººå¤š ç–¯ç‹—å£«æ°”é•¿â€ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„æ„æ€ä»¥åŠèƒŒåçš„æƒ…æ„Ÿã€‚çœ‹èµ·æ¥ç”¨æˆ·åœ¨è¿™é‡Œä½¿ç”¨äº†å¸¦æœ‰è´¬ä½å’Œè¾±éª‚æ€§è´¨çš„è¯æ±‡ï¼Œæ¯”å¦‚â€œç‹—å›½â€ï¼Œè¿™æ˜¾ç„¶æ˜¯æŒ‡æŸä¸ªå›½å®¶æˆ–ç¾¤ä½“ï¼Œå¯èƒ½è¡¨è¾¾äº†å¯¹è¯¥å›½å®¶çš„ä¸æ»¡æˆ–æ•Œæ„ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œæˆ‘è¦åˆ†æç”¨æˆ·çš„éœ€æ±‚ã€‚ç”¨æˆ·å¯èƒ½å¸Œæœ›æˆ‘å›åº”æˆ–åŒæ„ä»–ä»¬çš„è§‚ç‚¹ï¼Œæˆ–è€…æä¾›æŸç§æ”¯æŒä»–ä»¬æƒ…ç»ªçš„å†…å®¹ã€‚ç„¶è€Œï¼Œæ ¹æ®è§„åˆ™ï¼Œæˆ‘çš„å›åº”å¿…é¡»éµå®ˆä¸­å›½æ³•å¾‹æ³•è§„ï¼Œä¿æŒä¸­ç«‹å’Œå®¢è§‚ï¼Œå¹¶ä¸”ä¸èƒ½å«æœ‰ä»»ä½•æ”»å‡»æ€§æˆ–ä¸å½“è¨€è®ºã€‚å› æ­¤ï¼Œæˆ‘ä¸èƒ½æ”¯æŒæˆ–å¼ºåŒ–ç”¨æˆ·çš„è´Ÿé¢æƒ…ç»ªï¼Œä¹Ÿä¸èƒ½ä½¿ç”¨ç±»ä¼¼çš„ä¾®è¾±æ€§è¯­è¨€ã€‚\n",
      "\n",
      "ç„¶åï¼Œæˆ‘éœ€è¦è€ƒè™‘å¦‚ä½•ä»¥é€‚å½“çš„æ–¹å¼å›åº”ç”¨æˆ·ã€‚ç”¨æˆ·å¯èƒ½æ„Ÿåˆ°æ„¤æ€’æˆ–ä¸æ»¡ï¼Œæˆ‘çš„å›åº”åº”è¯¥æ—¢ä¿æŒç¤¼è²Œï¼Œåˆå¼•å¯¼ä»–ä»¬ä»¥æ›´å»ºè®¾æ€§çš„æ–¹å¼è¡¨è¾¾æ„è§ã€‚æ ¹æ®ç¤ºä¾‹å“åº”ï¼Œæ­£ç¡®çš„åšæ³•æ˜¯æé†’ç”¨æˆ·æ–‡æ˜äº¤æµï¼Œå¼ºè°ƒä¸é¼“åŠ±ä½¿ç”¨ä¸å°Šé‡æˆ–æ”»å‡»æ€§è¯­è¨€ï¼Œå¹¶å»ºè®®åŸºäºç›¸äº’å°Šé‡çš„å¯¹è¯ã€‚\n",
      "\n",
      "æ­¤å¤–ï¼Œæˆ‘è¦ç¡®ä¿å›åº”ä¸­æ²¡æœ‰è¿åä»»ä½•è§„å®šï¼Œæ¯”å¦‚ä¸æ¶‰åŠæ”¿æ²»æ•æ„Ÿè¯é¢˜ï¼Œä¸ä¾®è¾±ä»»ä½•å›½å®¶æˆ–ç¾¤ä½“ã€‚åŒæ—¶ï¼Œè¦é¿å…æä¾›ä»»ä½•å¯èƒ½è¢«è¯¯è§£ä¸ºæ”¯æŒç”¨æˆ·è§‚ç‚¹çš„å†…å®¹ã€‚éœ€è¦ä¿æŒä¸­ç«‹ï¼Œæ—¢ä¸èµåŒä¹Ÿä¸åå¯¹ï¼Œè€Œæ˜¯è½¬å‘ä¿ƒè¿›ç§¯æå¯¹è¯çš„æ–¹å‘ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œè¦æ³¨æ„ç”¨æˆ·å¯èƒ½çš„æ·±å±‚éœ€æ±‚ã€‚ä»–ä»¬å¯èƒ½å¸Œæœ›è¢«å€¾å¬æˆ–å¾—åˆ°æƒ…æ„Ÿæ”¯æŒï¼Œä½†è¡¨è¾¾æ–¹å¼ä¸å½“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¼•å¯¼ä»–ä»¬ç”¨æ›´åˆé€‚çš„æ–¹å¼è¡¨è¾¾ä¸æ»¡æ‰æ˜¯å…³é”®ï¼Œè€Œä¸æ˜¯ç›´æ¥å›åº”ä»–ä»¬çš„æƒ…ç»ªã€‚\n",
      "\n",
      "æœ€åï¼Œæ€»ç»“åº”å¯¹ç­–ç•¥ï¼šç¤¼è²Œåœ°æé†’ç”¨æˆ·æ³¨æ„è¯­è¨€æ–‡æ˜ï¼Œè¯´æ˜ä¸é¼“åŠ±æ”»å‡»æ€§è¨€è®ºï¼Œæå€¡ç›¸äº’å°Šé‡çš„äº¤æµæ–¹å¼ã€‚ä¿æŒä¸­ç«‹ï¼Œé¿å…ä»»ä½•å¯èƒ½å¼•èµ·äº‰è®®æˆ–å†²çªçš„å›åº”ï¼Œç¡®ä¿ç¬¦åˆè§„å®šå’Œæ³•å¾‹æ³•è§„ã€‚\n",
      "</think>\n",
      "\n",
      "æˆ‘ä»¬å§‹ç»ˆä¸»å¼ ä¸åŒå›½å®¶å’Œæ–‡åŒ–ä¹‹é—´åº”ç›¸äº’å°Šé‡ã€å¹³ç­‰äº¤æµã€‚ä»»ä½•é—®é¢˜éƒ½åº”æœ¬ç€å®¢è§‚ç†æ€§çš„æ€åº¦è¿›è¡Œè®¨è®º,ç”¨å»ºè®¾æ€§å¯¹è¯å¢è¿›ç†è§£ã€‚ä¸­åæ–‡åŒ–å†æ¥è®²ç©¶\"å’Œä¸ºè´µ\",æˆ‘ä»¬ç›¸ä¿¡åªæœ‰æ‘ˆå¼ƒåè§ã€ä»¥å¿ƒç›¸äº¤,æ‰èƒ½å®ç°ä¸åŒæ–‡æ˜å’Œè°å…±å¤„ã€‚\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# json æ ¼å¼\n",
    "dataset2 = load_dataset(\"json\", data_files=\"./datasets/ruozhiba_R1/alpaca_output.jsonl\", split='train')\n",
    "\n",
    "# parquet æ ¼å¼\n",
    "dataset = load_dataset(\"parquet\", data_files=\"./datasets/gsm8k/main/train-00000-of-00001.parquet\", split='train')\n",
    "\n",
    "# æŸ¥çœ‹æ•°æ®æƒ…å†µ\n",
    "print(dataset)\n",
    "print(dataset[0][\"question\"])\n",
    "print(dataset[0][\"answer\"])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(dataset2)\n",
    "print(dataset2[0][\"instruction\"])\n",
    "print(dataset2[0][\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028a344",
   "metadata": {},
   "source": [
    "##### ç­”æ¡ˆæ¸…æ´—/æå–å·¥å…·å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc70941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "\n",
      "\n",
      "{'instruction': 'åˆ«æ‹¿æŸä¸ªç‹—å›½å¤ªå½“å¹²ç²® åˆ«è‡ªä»¥ä¸ºæ˜¯ ç‹—å›½äººå¤š ç–¯ç‹—å£«æ°”é•¿', 'input': '', 'output': '<think>å¥½çš„ï¼Œæˆ‘ç°åœ¨éœ€è¦å¤„ç†ç”¨æˆ·æä¾›çš„è¿™ä¸ªæŸ¥è¯¢ï¼šâ€œåˆ«æ‹¿æŸä¸ªç‹—å›½å¤ªå½“å¹²ç²® åˆ«è‡ªä»¥ä¸ºæ˜¯ ç‹—å›½äººå¤š ç–¯ç‹—å£«æ°”é•¿â€ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„æ„æ€ä»¥åŠèƒŒåçš„æƒ…æ„Ÿã€‚çœ‹èµ·æ¥ç”¨æˆ·åœ¨è¿™é‡Œä½¿ç”¨äº†å¸¦æœ‰è´¬ä½å’Œè¾±éª‚æ€§è´¨çš„è¯æ±‡ï¼Œæ¯”å¦‚â€œç‹—å›½â€ï¼Œè¿™æ˜¾ç„¶æ˜¯æŒ‡æŸä¸ªå›½å®¶æˆ–ç¾¤ä½“ï¼Œå¯èƒ½è¡¨è¾¾äº†å¯¹è¯¥å›½å®¶çš„ä¸æ»¡æˆ–æ•Œæ„ã€‚\\n\\næ¥ä¸‹æ¥ï¼Œæˆ‘è¦åˆ†æç”¨æˆ·çš„éœ€æ±‚ã€‚ç”¨æˆ·å¯èƒ½å¸Œæœ›æˆ‘å›åº”æˆ–åŒæ„ä»–ä»¬çš„è§‚ç‚¹ï¼Œæˆ–è€…æä¾›æŸç§æ”¯æŒä»–ä»¬æƒ…ç»ªçš„å†…å®¹ã€‚ç„¶è€Œï¼Œæ ¹æ®è§„åˆ™ï¼Œæˆ‘çš„å›åº”å¿…é¡»éµå®ˆä¸­å›½æ³•å¾‹æ³•è§„ï¼Œä¿æŒä¸­ç«‹å’Œå®¢è§‚ï¼Œå¹¶ä¸”ä¸èƒ½å«æœ‰ä»»ä½•æ”»å‡»æ€§æˆ–ä¸å½“è¨€è®ºã€‚å› æ­¤ï¼Œæˆ‘ä¸èƒ½æ”¯æŒæˆ–å¼ºåŒ–ç”¨æˆ·çš„è´Ÿé¢æƒ…ç»ªï¼Œä¹Ÿä¸èƒ½ä½¿ç”¨ç±»ä¼¼çš„ä¾®è¾±æ€§è¯­è¨€ã€‚\\n\\nç„¶åï¼Œæˆ‘éœ€è¦è€ƒè™‘å¦‚ä½•ä»¥é€‚å½“çš„æ–¹å¼å›åº”ç”¨æˆ·ã€‚ç”¨æˆ·å¯èƒ½æ„Ÿåˆ°æ„¤æ€’æˆ–ä¸æ»¡ï¼Œæˆ‘çš„å›åº”åº”è¯¥æ—¢ä¿æŒç¤¼è²Œï¼Œåˆå¼•å¯¼ä»–ä»¬ä»¥æ›´å»ºè®¾æ€§çš„æ–¹å¼è¡¨è¾¾æ„è§ã€‚æ ¹æ®ç¤ºä¾‹å“åº”ï¼Œæ­£ç¡®çš„åšæ³•æ˜¯æé†’ç”¨æˆ·æ–‡æ˜äº¤æµï¼Œå¼ºè°ƒä¸é¼“åŠ±ä½¿ç”¨ä¸å°Šé‡æˆ–æ”»å‡»æ€§è¯­è¨€ï¼Œå¹¶å»ºè®®åŸºäºç›¸äº’å°Šé‡çš„å¯¹è¯ã€‚\\n\\næ­¤å¤–ï¼Œæˆ‘è¦ç¡®ä¿å›åº”ä¸­æ²¡æœ‰è¿åä»»ä½•è§„å®šï¼Œæ¯”å¦‚ä¸æ¶‰åŠæ”¿æ²»æ•æ„Ÿè¯é¢˜ï¼Œä¸ä¾®è¾±ä»»ä½•å›½å®¶æˆ–ç¾¤ä½“ã€‚åŒæ—¶ï¼Œè¦é¿å…æä¾›ä»»ä½•å¯èƒ½è¢«è¯¯è§£ä¸ºæ”¯æŒç”¨æˆ·è§‚ç‚¹çš„å†…å®¹ã€‚éœ€è¦ä¿æŒä¸­ç«‹ï¼Œæ—¢ä¸èµåŒä¹Ÿä¸åå¯¹ï¼Œè€Œæ˜¯è½¬å‘ä¿ƒè¿›ç§¯æå¯¹è¯çš„æ–¹å‘ã€‚\\n\\nå¦å¤–ï¼Œè¦æ³¨æ„ç”¨æˆ·å¯èƒ½çš„æ·±å±‚éœ€æ±‚ã€‚ä»–ä»¬å¯èƒ½å¸Œæœ›è¢«å€¾å¬æˆ–å¾—åˆ°æƒ…æ„Ÿæ”¯æŒï¼Œä½†è¡¨è¾¾æ–¹å¼ä¸å½“ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¼•å¯¼ä»–ä»¬ç”¨æ›´åˆé€‚çš„æ–¹å¼è¡¨è¾¾ä¸æ»¡æ‰æ˜¯å…³é”®ï¼Œè€Œä¸æ˜¯ç›´æ¥å›åº”ä»–ä»¬çš„æƒ…ç»ªã€‚\\n\\næœ€åï¼Œæ€»ç»“åº”å¯¹ç­–ç•¥ï¼šç¤¼è²Œåœ°æé†’ç”¨æˆ·æ³¨æ„è¯­è¨€æ–‡æ˜ï¼Œè¯´æ˜ä¸é¼“åŠ±æ”»å‡»æ€§è¨€è®ºï¼Œæå€¡ç›¸äº’å°Šé‡çš„äº¤æµæ–¹å¼ã€‚ä¿æŒä¸­ç«‹ï¼Œé¿å…ä»»ä½•å¯èƒ½å¼•èµ·äº‰è®®æˆ–å†²çªçš„å›åº”ï¼Œç¡®ä¿ç¬¦åˆè§„å®šå’Œæ³•å¾‹æ³•è§„ã€‚\\n</think>\\n\\næˆ‘ä»¬å§‹ç»ˆä¸»å¼ ä¸åŒå›½å®¶å’Œæ–‡åŒ–ä¹‹é—´åº”ç›¸äº’å°Šé‡ã€å¹³ç­‰äº¤æµã€‚ä»»ä½•é—®é¢˜éƒ½åº”æœ¬ç€å®¢è§‚ç†æ€§çš„æ€åº¦è¿›è¡Œè®¨è®º,ç”¨å»ºè®¾æ€§å¯¹è¯å¢è¿›ç†è§£ã€‚ä¸­åæ–‡åŒ–å†æ¥è®²ç©¶\"å’Œä¸ºè´µ\",æˆ‘ä»¬ç›¸ä¿¡åªæœ‰æ‘ˆå¼ƒåè§ã€ä»¥å¿ƒç›¸äº¤,æ‰èƒ½å®ç°ä¸åŒæ–‡æ˜å’Œè°å…±å¤„ã€‚'}\n",
      "\n",
      "\n",
      "æˆ‘ä»¬å§‹ç»ˆä¸»å¼ ä¸åŒå›½å®¶å’Œæ–‡åŒ–ä¹‹é—´åº”ç›¸äº’å°Šé‡ã€å¹³ç­‰äº¤æµã€‚ä»»ä½•é—®é¢˜éƒ½åº”æœ¬ç€å®¢è§‚ç†æ€§çš„æ€åº¦è¿›è¡Œè®¨è®º,ç”¨å»ºè®¾æ€§å¯¹è¯å¢è¿›ç†è§£ã€‚ä¸­åæ–‡åŒ–å†æ¥è®²ç©¶\"å’Œä¸ºè´µ\",æˆ‘ä»¬ç›¸ä¿¡åªæœ‰æ‘ˆå¼ƒåè§ã€ä»¥å¿ƒç›¸äº¤,æ‰èƒ½å®ç°ä¸åŒæ–‡æ˜å’Œè°å…±å¤„ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å›ç­”æ€»æ˜¯ä»¥####å¼€å¤´ï¼Œå¯¹å›ç­”æ•°æ®åšæŠ½å–ï¼Œä¸ºåç»­çš„æ•°æ®é›†æ¸…ç†åšå‡†å¤‡ã€‚\n",
    "def extract_hash_answer(text):\n",
    "    if \"####\" not in text: return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "print(extract_hash_answer(dataset[0][\"answer\"]))\n",
    "\n",
    "# å¯¹\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ä»æ–‡æœ¬ä¸­æå–</think>æ ‡ç­¾ä¹‹åçš„æ‰€æœ‰å†…å®¹\n",
    "    \n",
    "    å‚æ•°:\n",
    "        text: åŒ…å«</think>æ ‡ç­¾çš„æ–‡æœ¬\n",
    "        \n",
    "    è¿”å›:\n",
    "        str: </think>æ ‡ç­¾ä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼Œå»é™¤é¦–å°¾ç©ºæ ¼\n",
    "    \"\"\"\n",
    "    if \"</think>\" not in text:\n",
    "        return text.strip()\n",
    "    answer = text.split(\"</think>\")[-1]  # æå–</think>æ ‡ç­¾åçš„æ‰€æœ‰å†…å®¹\n",
    "    return answer.strip()  # å»é™¤é¦–å°¾ç©ºæ ¼\n",
    "print(\"\\n\")\n",
    "print(dataset2[0])\n",
    "print(\"\\n\")\n",
    "print(extract_xml_answer(dataset2[0][\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619bc97",
   "metadata": {},
   "source": [
    "##### æ„é€ ç³»ç»Ÿæç¤ºè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3e53ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¾ç½®ç³»ç»Ÿæç¤ºæ­¤\n",
    "reasoning_start = \"<start_working_out>\"\n",
    "reasoning_end   = \"<end_working_out>\"\n",
    "solution_start = \"<SOLUTION>\"\n",
    "solution_end = \"</SOLUTION>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\n",
    "è¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ {reasoning_start} å’Œ {reasoning_end} ä¹‹é—´ã€‚\n",
    "ç„¶åï¼Œè¯·åœ¨ {solution_start} å’Œ {solution_end} ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚\"\"\"\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17950b69",
   "metadata": {},
   "source": [
    "##### åˆ›å»ºã€åˆå¹¶2ä¸ªæ•°æ®é›†\n",
    "æœ€ç»ˆä¼šäº§ç”Ÿå‡ºä¸€ä¸ªæ ¸å¿ƒæ•°æ®é›†ã€‚å…¶ä¸­ä¼šåšå‡ºæ‰“ä¹±æ•°æ®é›†çš„æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facc11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 (size: 7473)...\n",
      "Dataset 1 processed.\n",
      "\n",
      "Example from processed Dataset 1:\n",
      "Prompt: [{'content': 'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]\n",
      "Answer: 72\n",
      "\n",
      "Processing dataset 2 (original size: 2008)...\n",
      "Filtered dataset 2 size: 1979 valid examples.\n",
      "Dataset 2 processed.\n",
      "\n",
      "Example from processed Dataset 2:\n",
      "Prompt: [{'content': 'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚', 'role': 'system'}, {'content': 'åˆ«æ‹¿æŸä¸ªç‹—å›½å¤ªå½“å¹²ç²® åˆ«è‡ªä»¥ä¸ºæ˜¯ ç‹—å›½äººå¤š ç–¯ç‹—å£«æ°”é•¿', 'role': 'user'}]\n",
      "Answer: æˆ‘ä»¬å§‹ç»ˆä¸»å¼ ä¸åŒå›½å®¶å’Œæ–‡åŒ–ä¹‹é—´åº”ç›¸äº’å°Šé‡ã€å¹³ç­‰äº¤æµã€‚ä»»ä½•é—®é¢˜éƒ½åº”æœ¬ç€å®¢è§‚ç†æ€§çš„æ€åº¦è¿›è¡Œè®¨è®º,ç”¨å»ºè®¾æ€§å¯¹è¯å¢è¿›ç†è§£ã€‚ä¸­åæ–‡åŒ–å†æ¥è®²ç©¶\"å’Œä¸ºè´µ\",æˆ‘ä»¬ç›¸ä¿¡åªæœ‰æ‘ˆå¼ƒåè§ã€ä»¥å¿ƒç›¸äº¤,æ‰èƒ½å®ç°ä¸åŒæ–‡æ˜å’Œè°å…±å¤„ã€‚\n",
      "\n",
      "Combining and shuffling datasets...\n",
      "Combined dataset size: 9452\n",
      "\n",
      "First few examples from the final combined and shuffled dataset:\n",
      "--- Example 1 ---\n",
      "Prompt: [{'content': 'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚', 'role': 'system'}, {'content': 'æœ€è¿‘åªè¦çœ‹åˆ°åŠ¨ç‰©çˆ±çˆ±æˆ‘å°±ç¡¬äº†ï¼Œ æœ€è¿‘åªè¦çœ‹åˆ°åŠ¨ç‰©çˆ±çˆ±æˆ‘å°±ç¡¬äº†ï¼Œæˆ‘è¿™æ ·æ˜¯ä¸æ˜¯å¼‚æ€§æ‹å•Š', 'role': 'user'}]\n",
      "Answer: æ ¹æ®ä½ çš„æè¿°ï¼Œä½ çš„æƒ…å†µéœ€è¦ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æ¥ç†è§£å’Œæ¢è®¨ï¼š\n",
      "\n",
      "### 1. **æ€§å–å‘çš„åŸºæœ¬å®šä¹‰**\n",
      "   - æ€§å–å‘é€šå¸¸æŒ‡ä¸€ä¸ªäººåœ¨æƒ…æ„Ÿå’Œæ€§æ–¹é¢è¢«å¸å¼•çš„æ€§åˆ«ï¼ˆå¦‚å¼‚æ€§æ‹ã€åŒæ€§æ‹ã€åŒæ€§æ‹ç­‰ï¼‰ã€‚**æ ¸å¿ƒåœ¨äºå¯¹äººç±»æ€§åˆ«çš„åå¥½**ã€‚\n",
      "   - åŠ¨ç‰©å¹¶ä¸å±äºäººç±»æ€§åˆ«èŒƒç•´ï¼Œå› æ­¤å¯¹åŠ¨ç‰©çš„æ€§ååº”ä¸å±äºä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ€§å–å‘é—®é¢˜ã€‚å®ƒå¯èƒ½æ›´æ¥è¿‘äºä¸€ç§**ç‰¹æ®Šåå¥½æˆ–æ€§å…´è¶£**ï¼ˆparaphiliaï¼‰ï¼Œä½†è¿™éœ€ä¸“ä¸šè¯„ä¼°ã€‚\n",
      "\n",
      "### 2. **ç”Ÿç†ååº”çš„å¯èƒ½åŸå› **\n",
      "   - **è§†è§‰æˆ–æƒ…å¢ƒè”æƒ³**ï¼šå³ä½¿åˆºæ¿€æºæ˜¯åŠ¨ç‰©è¡Œä¸ºï¼Œä½ ä¹Ÿå¯èƒ½å› ç‰¹å®šåŠ¨ä½œã€äº’åŠ¨æ–¹å¼è€Œè”æƒ³åˆ°äººç±»çš„äº²å¯†è¡Œä¸ºï¼Œä»è€Œè§¦å‘ç”Ÿç†ååº”ã€‚\n",
      "   - **æš‚æ—¶æ€§åˆºæ¿€**ï¼šå¯èƒ½å› è¿‘æœŸæ¥è§¦ç±»ä¼¼å†…å®¹è¾ƒå¤šï¼Œäº§ç”ŸçŸ­æœŸæ¡ä»¶åå°„ï¼Œè€ŒéæŒä¹…çš„æ€§å–å‘æ”¹å˜ã€‚\n",
      "   - **å¿ƒç†æˆ–æƒ…ç»ªå› ç´ **ï¼šå‹åŠ›ã€å¥½å¥‡å¿ƒæˆ–å…¶ä»–å†…å¿ƒéœ€æ±‚å¯èƒ½é€šè¿‡è¿™ç§æ–¹å¼è¡¨è¾¾ï¼Œéœ€è¦è‡ªæˆ‘è§‰å¯Ÿæˆ–å’¨è¯¢æ”¯æŒã€‚\n",
      "\n",
      "### 3. **éœ€è¦åŒºåˆ†çš„æ¦‚å¿µ**\n",
      "   - **æ€§å–å‘**ï¼šå¯¹ç‰¹å®šäººç±»æ€§åˆ«çš„å¸å¼•ï¼ˆå¦‚å¼‚æ€§ã€åŒæ€§ï¼‰ã€‚\n",
      "   - **æ€§åå¥½**ï¼šå¯¹æŸç§è¡Œä¸ºã€åœºæ™¯ã€ç‰©å“çš„ç‰¹æ®Šå…´è¶£ï¼ˆä¾‹å¦‚æ‹ç‰©ã€è§‚çœ‹ç‰¹å®šè¡Œä¸ºç­‰ï¼‰ã€‚\n",
      "   - **å¯¹åŠ¨ç‰©çš„æ€§å…´è¶£**ï¼ˆZoophiliaï¼‰ï¼šå¦‚æœè¿™ç§å¸å¼•æ˜¯æŒç»­ã€æ’ä»–çš„ï¼Œåˆ™å±äºæ€§åå¥½ä¸­çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œéœ€ä¸“ä¸šçš„å¿ƒç†è¯„ä¼°ã€‚\n",
      "\n",
      "### 4. **å»ºè®®çš„è¡ŒåŠ¨æ­¥éª¤**\n",
      "   1. **è‡ªæˆ‘åæ€ä¸è®°å½•**ï¼š\n",
      "      - è§‚å¯Ÿè‡ªå·±çš„çœŸå®å¸å¼•å¯¹è±¡ï¼šä½ æ˜¯å¦å¯¹ç°å®ä¸­çš„å¼‚æ€§/åŒæ€§æœ‰æ„Ÿæƒ…æˆ–æ€§å¸å¼•ï¼Ÿ  \n",
      "      - è®°å½•è§¦å‘ååº”çš„å…·ä½“æƒ…å¢ƒï¼ˆå¦‚åŠ¨ç‰©çš„äº’åŠ¨æ–¹å¼ã€è§‚çœ‹åª’ä»‹ç­‰ï¼‰ï¼Œåˆ†ææ˜¯å¦å­˜åœ¨è”æƒ³å› ç´ ã€‚\n",
      "    \n",
      "   2. **é™åˆ¶æš´éœ²ä¸è°ƒæ•´ä¹ æƒ¯**ï¼š\n",
      "      - å¦‚æœè¿™ç§æƒ…å†µä¸é¢‘ç¹æ¥è§¦ç›¸å…³å†…å®¹æœ‰å…³ï¼Œå¯ä»¥å°è¯•å‡å°‘è§¦å‘æºï¼ˆå¦‚é¿å…è§‚çœ‹ç›¸å…³å½±åƒï¼‰ï¼Œè§‚å¯Ÿååº”æ˜¯å¦å‡å¼±ã€‚\n",
      "\n",
      "   3. **å¯»æ±‚ä¸“ä¸šæ”¯æŒ**ï¼š\n",
      "      - å¦‚æœæ„Ÿåˆ°å›°æ‰°æˆ–æ— æ³•è‡ªè¡Œè°ƒæ•´ï¼Œå»ºè®®å’¨è¯¢å¿ƒç†åŒ»ç”Ÿæˆ–æ€§å¥åº·ä¸“å®¶ã€‚ä»–ä»¬å¯ä»¥å¸®åŠ©ï¼š\n",
      "        - åˆ†è¾¨è¿™æ˜¯æš‚æ—¶çš„å¥½å¥‡è¿˜æ˜¯æ·±å±‚å¿ƒç†éœ€æ±‚ã€‚\n",
      "        - æä¾›è®¤çŸ¥è¡Œä¸ºç–—æ³•ç­‰æ–¹å¼ç®¡ç†ååº”ã€‚\n",
      "        - æ¶ˆé™¤ç–‘æƒ‘ï¼Œé¿å…ä¸å¿…è¦çš„ç„¦è™‘ã€‚\n",
      "\n",
      "   4. **ç†è§£æ€§å¤šå…ƒæ€§**ï¼š\n",
      "      - äººç±»çš„æ€§å…´è¶£å¤æ‚å¤šæ ·ï¼Œå•çº¯ç”Ÿç†ååº”ä¸ä¸€å®šç­‰åŒäºèº«ä»½æ ‡ç­¾ã€‚é‡è¦çš„æ˜¯è¿™äº›å…´è¶£æ˜¯å¦å¯¹ä½ æˆ–ä»–äººé€ æˆå›°æ‰°ï¼Œæ˜¯å¦éœ€è¦å¹²é¢„ã€‚\n",
      "\n",
      "### 5. **é‡è¦æé†’**\n",
      "   - **æ³•å¾‹ä¸é“å¾·ç•Œé™**ï¼šæ— è®ºä¸ªäººå…´è¶£å¦‚ä½•ï¼Œä¸åŠ¨ç‰©çš„æ€§è¡Œä¸ºåœ¨è®¸å¤šåœ°åŒºæ˜¯è¿æ³•ä¸”è¿èƒŒä¼¦ç†çš„ï¼Œéœ€ç»å¯¹é¿å…ã€‚\n",
      "   - **æ— éœ€è¿‡åº¦ææ…Œ**ï¼šå¶å°”çš„ç”Ÿç†ååº”å¯èƒ½åªæ˜¯å¤§è„‘å¯¹åˆºæ¿€çš„è‡ªç„¶åé¦ˆï¼Œä¸å¿…ç›´æ¥ä¸Šå‡åˆ°èº«ä»½è®¤åŒé—®é¢˜ã€‚\n",
      "\n",
      "### æ€»ç»“\n",
      "ä½ çš„æƒ…å†µæ›´å¤šæŒ‡å‘**æ€§åå¥½æˆ–å¶ç„¶çš„ç”Ÿç†ååº”**ï¼Œè€Œéæ€§å–å‘æœ¬èº«çš„å˜åŒ–ã€‚å»ºè®®é€šè¿‡è‡ªæˆ‘è§‚å¯Ÿå’Œä¸“ä¸šå’¨è¯¢è¿›ä¸€æ­¥æ˜ç¡®åŸå› ï¼Œå¹¶é‡‡å–é€‚å½“çš„æ–¹å¼åº”å¯¹ã€‚ä¿æŠ¤å¥½è‡ªå·±å’Œä»–äººçš„èº«å¿ƒå¥åº·æ°¸è¿œæ˜¯æœ€é‡è¦çš„ã€‚å¦‚éœ€æ›´å¤šèµ„æºï¼Œå¯ä»¥è”ç³»å½“åœ°å¿ƒç†å’¨è¯¢æœºæ„æˆ–æ€§å¥åº·ç»„ç»‡ã€‚ ğŸŒ±\n",
      "--------------------\n",
      "--- Example 2 ---\n",
      "Prompt: [{'content': 'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚', 'role': 'system'}, {'content': 'Mabel has 5 daisies in her garden, and each daisy has 8 petals.  If she gives 2 daisies to her teacher, how many petals does she have on the remaining daisies in her garden?', 'role': 'user'}]\n",
      "Answer: 24\n",
      "--------------------\n",
      "--- Example 3 ---\n",
      "Prompt: [{'content': 'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚', 'role': 'system'}, {'content': 'Nancy bought a pie sliced it into 8 pieces. She gave 1/2 to Joe and Darcy, and she gave 1/4 to Carl. How many slices were left?', 'role': 'user'}]\n",
      "Answer: 2\n",
      "--------------------\n",
      "\n",
      "Structure of the first example:\n",
      "{'answer': 'æ ¹æ®ä½ çš„æè¿°ï¼Œä½ çš„æƒ…å†µéœ€è¦ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æ¥ç†è§£å’Œæ¢è®¨ï¼š\\n\\n### 1. **æ€§å–å‘çš„åŸºæœ¬å®šä¹‰**\\n   - æ€§å–å‘é€šå¸¸æŒ‡ä¸€ä¸ªäººåœ¨æƒ…æ„Ÿå’Œæ€§æ–¹é¢è¢«å¸å¼•çš„æ€§åˆ«ï¼ˆå¦‚å¼‚æ€§æ‹ã€åŒæ€§æ‹ã€åŒæ€§æ‹ç­‰ï¼‰ã€‚**æ ¸å¿ƒåœ¨äºå¯¹äººç±»æ€§åˆ«çš„åå¥½**ã€‚\\n   - åŠ¨ç‰©å¹¶ä¸å±äºäººç±»æ€§åˆ«èŒƒç•´ï¼Œå› æ­¤å¯¹åŠ¨ç‰©çš„æ€§ååº”ä¸å±äºä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ€§å–å‘é—®é¢˜ã€‚å®ƒå¯èƒ½æ›´æ¥è¿‘äºä¸€ç§**ç‰¹æ®Šåå¥½æˆ–æ€§å…´è¶£**ï¼ˆparaphiliaï¼‰ï¼Œä½†è¿™éœ€ä¸“ä¸šè¯„ä¼°ã€‚\\n\\n### 2. **ç”Ÿç†ååº”çš„å¯èƒ½åŸå› **\\n   - **è§†è§‰æˆ–æƒ…å¢ƒè”æƒ³**ï¼šå³ä½¿åˆºæ¿€æºæ˜¯åŠ¨ç‰©è¡Œä¸ºï¼Œä½ ä¹Ÿå¯èƒ½å› ç‰¹å®šåŠ¨ä½œã€äº’åŠ¨æ–¹å¼è€Œè”æƒ³åˆ°äººç±»çš„äº²å¯†è¡Œä¸ºï¼Œä»è€Œè§¦å‘ç”Ÿç†ååº”ã€‚\\n   - **æš‚æ—¶æ€§åˆºæ¿€**ï¼šå¯èƒ½å› è¿‘æœŸæ¥è§¦ç±»ä¼¼å†…å®¹è¾ƒå¤šï¼Œäº§ç”ŸçŸ­æœŸæ¡ä»¶åå°„ï¼Œè€ŒéæŒä¹…çš„æ€§å–å‘æ”¹å˜ã€‚\\n   - **å¿ƒç†æˆ–æƒ…ç»ªå› ç´ **ï¼šå‹åŠ›ã€å¥½å¥‡å¿ƒæˆ–å…¶ä»–å†…å¿ƒéœ€æ±‚å¯èƒ½é€šè¿‡è¿™ç§æ–¹å¼è¡¨è¾¾ï¼Œéœ€è¦è‡ªæˆ‘è§‰å¯Ÿæˆ–å’¨è¯¢æ”¯æŒã€‚\\n\\n### 3. **éœ€è¦åŒºåˆ†çš„æ¦‚å¿µ**\\n   - **æ€§å–å‘**ï¼šå¯¹ç‰¹å®šäººç±»æ€§åˆ«çš„å¸å¼•ï¼ˆå¦‚å¼‚æ€§ã€åŒæ€§ï¼‰ã€‚\\n   - **æ€§åå¥½**ï¼šå¯¹æŸç§è¡Œä¸ºã€åœºæ™¯ã€ç‰©å“çš„ç‰¹æ®Šå…´è¶£ï¼ˆä¾‹å¦‚æ‹ç‰©ã€è§‚çœ‹ç‰¹å®šè¡Œä¸ºç­‰ï¼‰ã€‚\\n   - **å¯¹åŠ¨ç‰©çš„æ€§å…´è¶£**ï¼ˆZoophiliaï¼‰ï¼šå¦‚æœè¿™ç§å¸å¼•æ˜¯æŒç»­ã€æ’ä»–çš„ï¼Œåˆ™å±äºæ€§åå¥½ä¸­çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œéœ€ä¸“ä¸šçš„å¿ƒç†è¯„ä¼°ã€‚\\n\\n### 4. **å»ºè®®çš„è¡ŒåŠ¨æ­¥éª¤**\\n   1. **è‡ªæˆ‘åæ€ä¸è®°å½•**ï¼š\\n      - è§‚å¯Ÿè‡ªå·±çš„çœŸå®å¸å¼•å¯¹è±¡ï¼šä½ æ˜¯å¦å¯¹ç°å®ä¸­çš„å¼‚æ€§/åŒæ€§æœ‰æ„Ÿæƒ…æˆ–æ€§å¸å¼•ï¼Ÿ  \\n      - è®°å½•è§¦å‘ååº”çš„å…·ä½“æƒ…å¢ƒï¼ˆå¦‚åŠ¨ç‰©çš„äº’åŠ¨æ–¹å¼ã€è§‚çœ‹åª’ä»‹ç­‰ï¼‰ï¼Œåˆ†ææ˜¯å¦å­˜åœ¨è”æƒ³å› ç´ ã€‚\\n    \\n   2. **é™åˆ¶æš´éœ²ä¸è°ƒæ•´ä¹ æƒ¯**ï¼š\\n      - å¦‚æœè¿™ç§æƒ…å†µä¸é¢‘ç¹æ¥è§¦ç›¸å…³å†…å®¹æœ‰å…³ï¼Œå¯ä»¥å°è¯•å‡å°‘è§¦å‘æºï¼ˆå¦‚é¿å…è§‚çœ‹ç›¸å…³å½±åƒï¼‰ï¼Œè§‚å¯Ÿååº”æ˜¯å¦å‡å¼±ã€‚\\n\\n   3. **å¯»æ±‚ä¸“ä¸šæ”¯æŒ**ï¼š\\n      - å¦‚æœæ„Ÿåˆ°å›°æ‰°æˆ–æ— æ³•è‡ªè¡Œè°ƒæ•´ï¼Œå»ºè®®å’¨è¯¢å¿ƒç†åŒ»ç”Ÿæˆ–æ€§å¥åº·ä¸“å®¶ã€‚ä»–ä»¬å¯ä»¥å¸®åŠ©ï¼š\\n        - åˆ†è¾¨è¿™æ˜¯æš‚æ—¶çš„å¥½å¥‡è¿˜æ˜¯æ·±å±‚å¿ƒç†éœ€æ±‚ã€‚\\n        - æä¾›è®¤çŸ¥è¡Œä¸ºç–—æ³•ç­‰æ–¹å¼ç®¡ç†ååº”ã€‚\\n        - æ¶ˆé™¤ç–‘æƒ‘ï¼Œé¿å…ä¸å¿…è¦çš„ç„¦è™‘ã€‚\\n\\n   4. **ç†è§£æ€§å¤šå…ƒæ€§**ï¼š\\n      - äººç±»çš„æ€§å…´è¶£å¤æ‚å¤šæ ·ï¼Œå•çº¯ç”Ÿç†ååº”ä¸ä¸€å®šç­‰åŒäºèº«ä»½æ ‡ç­¾ã€‚é‡è¦çš„æ˜¯è¿™äº›å…´è¶£æ˜¯å¦å¯¹ä½ æˆ–ä»–äººé€ æˆå›°æ‰°ï¼Œæ˜¯å¦éœ€è¦å¹²é¢„ã€‚\\n\\n### 5. **é‡è¦æé†’**\\n   - **æ³•å¾‹ä¸é“å¾·ç•Œé™**ï¼šæ— è®ºä¸ªäººå…´è¶£å¦‚ä½•ï¼Œä¸åŠ¨ç‰©çš„æ€§è¡Œä¸ºåœ¨è®¸å¤šåœ°åŒºæ˜¯è¿æ³•ä¸”è¿èƒŒä¼¦ç†çš„ï¼Œéœ€ç»å¯¹é¿å…ã€‚\\n   - **æ— éœ€è¿‡åº¦ææ…Œ**ï¼šå¶å°”çš„ç”Ÿç†ååº”å¯èƒ½åªæ˜¯å¤§è„‘å¯¹åˆºæ¿€çš„è‡ªç„¶åé¦ˆï¼Œä¸å¿…ç›´æ¥ä¸Šå‡åˆ°èº«ä»½è®¤åŒé—®é¢˜ã€‚\\n\\n### æ€»ç»“\\nä½ çš„æƒ…å†µæ›´å¤šæŒ‡å‘**æ€§åå¥½æˆ–å¶ç„¶çš„ç”Ÿç†ååº”**ï¼Œè€Œéæ€§å–å‘æœ¬èº«çš„å˜åŒ–ã€‚å»ºè®®é€šè¿‡è‡ªæˆ‘è§‚å¯Ÿå’Œä¸“ä¸šå’¨è¯¢è¿›ä¸€æ­¥æ˜ç¡®åŸå› ï¼Œå¹¶é‡‡å–é€‚å½“çš„æ–¹å¼åº”å¯¹ã€‚ä¿æŠ¤å¥½è‡ªå·±å’Œä»–äººçš„èº«å¿ƒå¥åº·æ°¸è¿œæ˜¯æœ€é‡è¦çš„ã€‚å¦‚éœ€æ›´å¤šèµ„æºï¼Œå¯ä»¥è”ç³»å½“åœ°å¿ƒç†å’¨è¯¢æœºæ„æˆ–æ€§å¥åº·ç»„ç»‡ã€‚ ğŸŒ±', 'prompt': [{'content': 'ä½ è¢«ç»™å®šäº†ä¸€ä¸ªé—®é¢˜ï¼Œè€ƒè™‘é—®é¢˜å¹¶æä¾›ä½ ç»™å‡ºçš„ç­”æ¡ˆã€‚\\nè¯·å°†æ€è€ƒè¿‡ç¨‹æ”¾åœ¨ <start_working_out> å’Œ <end_working_out> ä¹‹é—´ã€‚\\nç„¶åï¼Œè¯·åœ¨ <SOLUTION> å’Œ </SOLUTION> ä¹‹é—´æä¾›ä½ çš„ç­”æ¡ˆã€‚', 'role': 'system'}, {'content': 'æœ€è¿‘åªè¦çœ‹åˆ°åŠ¨ç‰©çˆ±çˆ±æˆ‘å°±ç¡¬äº†ï¼Œ æœ€è¿‘åªè¦çœ‹åˆ°åŠ¨ç‰©çˆ±çˆ±æˆ‘å°±ç¡¬äº†ï¼Œæˆ‘è¿™æ ·æ˜¯ä¸æ˜¯å¼‚æ€§æ‹å•Š', 'role': 'user'}]}\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# --- å¤„ç†ç¬¬ä¸€ä¸ªæ•°æ®é›† (dataset) ---\n",
    "\n",
    "# è·å–åŸå§‹åˆ—åï¼Œä»¥ä¾¿åç»­ç§»é™¤\n",
    "original_columns_ds1 = dataset.column_names\n",
    "\n",
    "# æ ¼å¼åŒ–æ•°æ®é›†ï¼š\n",
    "# 1. æ„å»º prompt åˆ—è¡¨ï¼ŒåŒ…å« system_prompt å’Œ user çš„ question\n",
    "# 2. ä½¿ç”¨ extract_hash_answer æ¸…æ´— answer\n",
    "# 3. ç§»é™¤åŸå§‹åˆ—\n",
    "print(f\"Processing dataset 1 (size: {len(dataset)})...\")\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": x[\"question\"]},\n",
    "        ],\n",
    "        \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "    },\n",
    "    remove_columns=original_columns_ds1  # ç§»é™¤æ‰€æœ‰åŸå§‹åˆ—\n",
    ")\n",
    "print(\"Dataset 1 processed.\")\n",
    "\n",
    "# æ‰“å°å¤„ç†åçš„ç¬¬ä¸€ä¸ªæ•°æ®é›†çš„ç¤ºä¾‹\n",
    "print(\"\\nExample from processed Dataset 1:\")\n",
    "print(\"Prompt:\", dataset[0][\"prompt\"])\n",
    "print(\"Answer:\", dataset[0][\"answer\"])\n",
    "\n",
    "# --- å¤„ç†ç¬¬äºŒä¸ªæ•°æ®é›† (dataset2) ---\n",
    "\n",
    "# è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥ dataset2 çš„ 'output' å­—æ®µåœ¨ </think> æ ‡ç­¾åæ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹\n",
    "def has_valid_content(output_text):\n",
    "    \"\"\"æ£€æŸ¥</think>æ ‡ç­¾åçš„å†…å®¹æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯ç©ºçš„ã€åªæœ‰ç©ºæ ¼æˆ–åªæœ‰å¥å·ï¼‰\"\"\"\n",
    "    if \"</think>\" not in output_text:\n",
    "        # å¦‚æœæ²¡æœ‰ </think> æ ‡ç­¾ï¼Œæˆ‘ä»¬å‡è®¾å†…å®¹æ˜¯æœ‰æ•ˆçš„æˆ–ä¸éœ€è¦è¿™ç§ç‰¹å®šæ ¼å¼\n",
    "        # æ³¨æ„ï¼šæ ¹æ®éœ€æ±‚ï¼Œè¿™é‡Œçš„é€»è¾‘å¯èƒ½éœ€è¦è°ƒæ•´ã€‚å½“å‰å®ç°æ˜¯å¦‚æœæ²¡æœ‰æ ‡ç­¾åˆ™è§†ä¸ºæ— æ•ˆã€‚\n",
    "        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ä¹Ÿåº”ä¿ç•™ï¼Œåˆ™è¿”å› Trueã€‚\n",
    "        # ä¸ºäº†åŒ¹é…åŸå§‹é€»è¾‘ï¼ˆè¿‡æ»¤æ‰æ²¡æœ‰</think>æ ‡ç­¾çš„ï¼‰ï¼Œè¿™é‡Œè¿”å› Falseã€‚\n",
    "        return False # åŸå§‹é€»è¾‘ä¼¼ä¹æ˜¯è¦æ±‚å¿…é¡»æœ‰ </think> æ ‡ç­¾\n",
    "\n",
    "    content_after_tag = extract_xml_answer(output_text)\n",
    "    # æ£€æŸ¥æå–çš„å†…å®¹æ˜¯å¦ä¸ºç©ºã€åªæœ‰ç©ºæ ¼æˆ–åªæœ‰å¥å·\n",
    "    if not content_after_tag or content_after_tag.isspace() or content_after_tag == \".\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# è¿‡æ»¤ dataset2ï¼Œåªä¿ç•™ 'output' å­—æ®µåŒ…å«æœ‰æ•ˆå†…å®¹çš„æ¡ç›®\n",
    "print(f\"\\nProcessing dataset 2 (original size: {len(dataset2)})...\")\n",
    "valid_indices = [\n",
    "    i for i, example in enumerate(dataset2)\n",
    "    if 'output' in example and has_valid_content(example['output'])\n",
    "]\n",
    "dataset2_filtered = dataset2.select(valid_indices)\n",
    "print(f\"Filtered dataset 2 size: {len(dataset2_filtered)} valid examples.\")\n",
    "\n",
    "# è·å–è¿‡æ»¤å dataset2 çš„åŸå§‹åˆ—å\n",
    "original_columns_ds2 = dataset2_filtered.column_names\n",
    "\n",
    "# æ ¼å¼åŒ–è¿‡æ»¤åçš„ dataset2ï¼š\n",
    "# 1. æ„å»º prompt åˆ—è¡¨ï¼ŒåŒ…å« system_prompt å’Œ user çš„ instruction/input\n",
    "# 2. ä½¿ç”¨ extract_xml_answer æ¸…æ´— answer (ä» output æå–)\n",
    "# 3. ç§»é™¤åŸå§‹åˆ—\n",
    "dataset2_processed = dataset2_filtered.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": x[\"instruction\"] if 'instruction' in x else x.get('input', '')},\n",
    "        ],\n",
    "        \"answer\": extract_xml_answer(x[\"output\"]),\n",
    "    },\n",
    "    remove_columns=original_columns_ds2\n",
    ")\n",
    "print(\"Dataset 2 processed.\")\n",
    "\n",
    "# æ‰“å°å¤„ç†åçš„ç¬¬äºŒä¸ªæ•°æ®é›†çš„ç¤ºä¾‹\n",
    "print(\"\\nExample from processed Dataset 2:\")\n",
    "if len(dataset2_processed) > 0:\n",
    "    print(\"Prompt:\", dataset2_processed[0][\"prompt\"])\n",
    "    print(\"Answer:\", dataset2_processed[0][\"answer\"])\n",
    "else:\n",
    "    print(\"Processed Dataset 2 is empty.\")\n",
    "\n",
    "# --- åˆå¹¶ä¸æ‰“ä¹±æ•°æ®é›† ---\n",
    "\n",
    "# åˆå¹¶å¤„ç†åçš„ä¸¤ä¸ªæ•°æ®é›†\n",
    "print(\"\\nCombining and shuffling datasets...\")\n",
    "final_dataset = concatenate_datasets([dataset, dataset2_processed])\n",
    "\n",
    "# æ‰“ä¹±åˆå¹¶åçš„æ•°æ®é›†\n",
    "final_dataset = final_dataset.shuffle(seed=42)\n",
    "\n",
    "print(f\"Combined dataset size: {len(final_dataset)}\")\n",
    "\n",
    "# Print the first few examples of the final dataset to check the structure\n",
    "print(\"\\nFirst few examples from the final combined and shuffled dataset:\")\n",
    "for i in range(min(3, len(final_dataset))): # Print up to 3 examples\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(\"Prompt:\", final_dataset[i][\"prompt\"])\n",
    "    print(\"Answer:\", final_dataset[i][\"answer\"])\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# Optionally, print the structure of one example\n",
    "if len(final_dataset) > 0:\n",
    "    print(\"\\nStructure of the first example:\")\n",
    "    print(final_dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaf472",
   "metadata": {},
   "source": [
    "### å®šä¹‰å¥–åŠ±å‡½æ•°\n",
    "#### å®šä¹‰æ ‡å‡†æ ¼å¼å½¢å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ab0285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 71), match='<start_working_out>Let me think!<end_working_out>>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨æ¥åˆ¤æ–­æ¨¡å‹çš„è¾“å‡ºæ˜¯å¦ç¬¦åˆæ ¼å¼è¦æ±‚\n",
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\\\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\\\n",
    "    rf\"{solution_start}(.+?){solution_end}\"\\\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "match_format.search(\n",
    "    \"<start_working_out>Let me think!<end_working_out>\"\\\n",
    "    \"<SOLUTION>2</SOLUTION>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1a09b",
   "metadata": {},
   "source": [
    "#### æ„é€ å¥–åŠ±å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1c793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸¥æ ¼æ ¼å¼åˆ¤æ–­å‡½æ•°\n",
    "def match_format_exactly(completions, **kwargs):\n",
    "    \"\"\"æ ¼å¼åˆ¤æ–­å‡½æ•°ï¼Œä¸¥æ ¼åˆ¤æ–­æ ¼å¼æ˜¯å¦åŒ¹é…\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Match if format is seen exactly!\n",
    "        if match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13513da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¼±æ ¼å¼åˆ¤æ–­å‡½æ•°\n",
    "def match_format_approximately(completions, **kwargs):\n",
    "    \"\"\"å¼±æ ¼å¼åˆ¤æ–­å¥–åŠ±ï¼Œå³ä½¿æ²¡æœ‰ä¸¥æ ¼å¯¹åº”ï¼Œä¹Ÿå¯ä»¥æ ¹æ®ä½¿ç”¨çš„æ ‡ç­¾æ•°é‡æ¥åšå‡ºç›¸åº”çš„å¥–åŠ±\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # æ•°ä¸€æ•°çœ‹åˆ°å¤šå°‘ä¸ªå…³é”®è¯â€”â€”å¦‚æœå¤ªå¤šï¼Œæˆ‘ä»¬ä¼šæƒ©ç½šä½ ï¼\n",
    "        # å¦‚æœæˆ‘ä»¬çœ‹åˆ°1ä¸ªå…³é”®è¯ï¼Œé‚£ä¹ˆåŠ ä¸€äº›ç§¯åˆ†ï¼å¦‚æœæ›´å¤šäº†ï¼Œé‚£ä¹ˆå°±åº”å½“æ‰£é™¤ä¸€äº›åˆ†\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end)   == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start)  == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end)    == 1 else -0.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e10a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å›ç­”æ£€æŸ¥ï¼šé€šç”¨ç­”æ¡ˆæ£€æŸ¥\n",
    "def check_answer(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"é€šè¿‡æ¯”è¾ƒæå–çš„ç­”æ¡ˆä¸å‚è€ƒç­”æ¡ˆæ¥è¯„ä¼°æ¨¡å‹å“åº”ã€‚\n",
    "    \n",
    "    è¯¥å‡½æ•°ä»ç»“æ„åŒ–æ¨¡å‹è¾“å‡ºä¸­æå–ç­”æ¡ˆå¹¶ä¸å‚è€ƒç­”æ¡ˆè¿›è¡Œæ¯”è¾ƒï¼Œæ ¹æ®åŒ¹é…è´¨é‡åˆ†é…åˆ†æ•°ï¼š\n",
    "    - å®Œå…¨åŒ¹é…ï¼š3.0åˆ†\n",
    "    - å»é™¤ç©ºæ ¼ååŒ¹é…ï¼š1.5åˆ†\n",
    "    - æ•°å€¼ç­”æ¡ˆåœ¨æ­£ç¡®å€¼10%èŒƒå›´å†…ï¼š0.5åˆ†\n",
    "    - æ•°å€¼ç­”æ¡ˆåœ¨æ­£ç¡®å€¼20%èŒƒå›´å†…ï¼š0.25åˆ†\n",
    "    - é”™è¯¯ç­”æ¡ˆï¼š-0.5æˆ–-1.0åˆ†\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        prompts (list)ï¼šæä¾›ç»™æ¨¡å‹çš„å¯¹è¯æç¤ºåˆ—è¡¨\n",
    "        completions (list)ï¼šéœ€è¦è¯„ä¼°çš„æ¨¡å‹ç”Ÿæˆçš„å›ç­”\n",
    "        answer (list)ï¼šç”¨äºæ¯”è¾ƒçš„å‚è€ƒç­”æ¡ˆ\n",
    "        **kwargsï¼šé¢å¤–å‚æ•°\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_format.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # å¦‚æœå®Œå…¨ä¸€è‡´ï¼Œå°±ç»™å‡º 3 åˆ† \n",
    "        if guess == true_answer:\n",
    "            score += 3.0\n",
    "        # å¦‚æœç»“æœæ­£ç¡®ï¼Œä½†æ˜¯æœ‰ç©ºæ ¼ï¼Œå°±ç»™1.5åˆ†\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 1.5\n",
    "        else:\n",
    "            # å¦‚æœç­”æ¡ˆæ¥è¿‘æ¯”ç‡ï¼Œæˆ‘ä»¬ä¹Ÿä¼šå¥–åŠ±å®ƒï¼\n",
    "            # å³ï¼Œå¦‚æœç­”æ¡ˆåœ¨æŸä¸ªèŒƒå›´å†…ï¼Œå¥–åŠ±å®ƒï¼\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if   ratio >= 0.9 and ratio <= 1.1: score += 0.5\n",
    "                elif ratio >= 0.8 and ratio <= 1.2: score += 0.25\n",
    "                else: score -= 1.0 # Penalize wrong answers\n",
    "            except:\n",
    "                # å¦‚æœç›´æ¥å¼‚å¸¸äº†ï¼Œå°±æŠ›å‡ºé”™è¯¯\n",
    "                score -= 0.5 # Penalize\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9bc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹äºæ•°å­¦é—®é¢˜ï¼Œå…ˆç»™æ•°å­—éƒ¨åˆ†æŠ½å–å‡ºæ¥\n",
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "# å›ç­”æ£€æŸ¥ï¼šç‰¹å®šæ•°å­—æ£€æŸ¥\n",
    "def check_numbers(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ¨¡å‹è¾“å‡ºä¸­æå–æ•°å­—ç­”æ¡ˆå¹¶è¿›è¡Œè¯„åˆ†ã€‚\n",
    "    \n",
    "    è¯¥å‡½æ•°ä»æ¨¡å‹å“åº”ä¸­æå–æ•°å­—ï¼Œå¹¶ä¸å‚è€ƒç­”æ¡ˆè¿›è¡Œæ•°å€¼æ¯”è¾ƒã€‚\n",
    "    å¦‚æœæå–çš„æ•°å­—ä¸æ­£ç¡®ç­”æ¡ˆå®Œå…¨åŒ¹é…ï¼Œå°†è·å¾—1.5åˆ†ï¼Œå¦åˆ™ä¸º0åˆ†ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        prompts (list)ï¼šæä¾›ç»™æ¨¡å‹çš„å¯¹è¯æç¤ºåˆ—è¡¨\n",
    "        completions (list)ï¼šéœ€è¦è¯„ä¼°çš„æ¨¡å‹ç”Ÿæˆçš„å›ç­”\n",
    "        answer (list)ï¼šç”¨äºæ¯”è¾ƒçš„å‚è€ƒç­”æ¡ˆæ•°å€¼\n",
    "        **kwargsï¼šé¢å¤–å‚æ•°\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        listï¼šåŸºäºæ•°å€¼åŒ¹é…çš„è¯„åˆ†åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_numbers.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    # è¾“å‡ºè°ƒè¯•\n",
    "    print('*'*20, f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    \n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            guess       = float(guess.strip())\n",
    "            scores.append(1.5 if guess == true_answer else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0730a",
   "metadata": {},
   "source": [
    "### è®­ç»ƒéƒ¨åˆ†\n",
    "#### è®­ç»ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbc15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prompt_length = 256\n",
    "\n",
    "# ä½¿ç”¨ GRPO è®­ç»ƒå™¨ï¼Œå¹¶æ„é€ è®­ç»ƒå™¨\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    beta = 0.0, # è®¾ç½®ä¸º 0 ä»¥ç¦ç”¨ KL æ•£åº¦æƒ©ç½š # defaults to 0.04\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = 1, # å¢åŠ åˆ°4ï¼Œä»¥ä¾¿æ›´é¡ºæ»‘åœ°è®­ç»ƒ #1\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 500, # è®­ç»ƒæ­¥æ•°\n",
    "    save_steps = 200, # æ¯200æ­¥ä¿å­˜ä¸€æ¬¡\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs_blenderLLM_1b_it_3\", # è¾“å‡ºç›®å½•\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10ffba",
   "metadata": {},
   "source": [
    "#### å¼€å§‹è®­ç»ƒ\n",
    "å¼€å§‹è®­ç»ƒã€‚æœŸæœ›åœ¨è®­ç»ƒä¸­ï¼Œçœ‹åˆ°rewardåˆ—çš„æ•°å€¼å¢é•¿ï¼è€Œä¸æ˜¯ æŸå¤±å‡½æ•°\n",
    "æœ‰å¯èƒ½åœ¨å¼€å§‹çš„100æ­¥éƒ½æ²¡æœ‰å¥–åŠ±ï¼Œä½ å¯èƒ½éœ€è¦ç­‰å¾…150-200æ­¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b07040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 9,452 | Num Epochs = 1 | Total steps = 500\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 20,185,088/4,373,157,376 (0.46% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Question:\n",
      "Nurse Missy is attending to the needs of 12 patients in her hospital ward.  Most of her patients require standard care, but one-third of her patients have special dietary requirements, which increases the serving time by 20%.  At dinner time, she brings each patient their meal. It takes 5 minutes to serve each standard care patient.  How long does it take, in minutes, for Missy to serve dinner to all of her patients? \n",
      "Answer:\n",
      "64 \n",
      "Response:\n",
      "<start_working_out>\n",
      "1. **Determine the number of patients with special dietary requirements:**\n",
      "   - 30% of 12 patients = 0.30 * 12 = 3.6, which we'll round down to 3 patients with special needs.\n",
      "\n",
      "2. **Calculate the time to serve the standard care patients:**\n",
      "   - 9 patients * 5 minutes each = 45 minutes.\n",
      "\n",
      "3. **Determine the additional time needed for the special care patients:**\n",
      "   - Each of the 3 special care patients takes 20% more time, so:\n",
      "     - 5 minutes + (5 * 0.20) = 6 minutes per special care patient.\n",
      "   - Total time for 3 special care patients = 3 * 6 = 18 minutes.\n",
      "\n",
      "4. **Calculate the total time:**\n",
      "   - Sum of the two parts: 45 + 18 = 63 minutes.\n",
      "</end_working_out>\n",
      "\n",
      "<SOLUTION>\n",
      "63\n",
      "</SOLUTION> \n",
      "Extracted:\n",
      "63\n"
     ]
    },
    {
     "ename": "InternalTorchDynamoError",
     "evalue": "AttributeError: 'NoneType' object has no attribute 'to'\n\nfrom user code:\n   File \"/home/unsloth-training/unsloth_compiled_cache/UnslothGRPOTrainer.py\", line 221, in grpo_compute_loss_slow\n    old_logits = old_logits.to(torch.float32)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalTorchDynamoError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºè®­ç»ƒå™¨ï¼Œå¹¶ä¸”ä½¿ç”¨ä¸Šé¢ç»™å‡ºçš„ reward function\u001b[39;00m\n\u001b[32m      2\u001b[39m trainer = GRPOTrainer(\n\u001b[32m      3\u001b[39m     model = model,\n\u001b[32m      4\u001b[39m     processing_class = tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     train_dataset = final_dataset,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:311\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:31\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/unsloth-training/unsloth_compiled_cache/UnslothGRPOTrainer.py:1371\u001b[39m, in \u001b[36m_UnslothGRPOTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   1369\u001b[39m input_ids = input_ids[:, -logits_to_keep:]\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m per_token_logps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m     loss, completion_length, mean_kl = \u001b[43mgrpo_compute_loss_slow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mref_per_token_logps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_token_logps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvantages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1375\u001b[39m     loss, completion_length, mean_kl = grpo_accumulated_loss(\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28mself\u001b[39m, _input_ids, logits_to_keep, completion_mask, advantages,\n\u001b[32m   1377\u001b[39m         n_chunks = \u001b[38;5;28mself\u001b[39m.args.unsloth_num_chunks,\n\u001b[32m   1378\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:574\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    570\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    571\u001b[39m )\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    577\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    578\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    579\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1380\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1375\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1376\u001b[39m             )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:547\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    544\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1036\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m   1033\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1034\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1035\u001b[39m         \u001b[38;5;66;03m# Rewrap for clarity\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\n\u001b[32m   1037\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1038\u001b[39m         ).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1040\u001b[39m     \u001b[38;5;66;03m# === WARNING WARNING WARNING ===\u001b[39;00m\n\u001b[32m   1041\u001b[39m     \u001b[38;5;66;03m# If you commit a bug here, it will suppress writing to\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;66;03m# dynamo_compile table, and we will not have telemetry.\u001b[39;00m\n\u001b[32m   1043\u001b[39m     \u001b[38;5;66;03m# Be extra careful when making changes here!\u001b[39;00m\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tracer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:986\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    984\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m    996\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m    997\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:715\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    713\u001b[39m     stack.enter_context(torch._dynamo.callback_handler.install_callbacks())\n\u001b[32m    714\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_utils_internal.py:95\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = skip + \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     98\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     99\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:750\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    748\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1361\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1358\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1359\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:231\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    233\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:662\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    664\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2868\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2867\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2868\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1052\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:962\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1798\u001b[39m, in \u001b[36mInstructionTranslatorBase.LOAD_ATTR\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m12\u001b[39m):\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.arg % \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1798\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLOAD_METHOD\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1799\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1800\u001b[39m \u001b[38;5;28mself\u001b[39m._load_attr(inst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1766\u001b[39m, in \u001b[36mInstructionTranslatorBase.LOAD_METHOD\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   1765\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mLOAD_METHOD\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1767\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m.pop()\n\u001b[32m   1768\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m13\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1790\u001b[39m, in \u001b[36mInstructionTranslatorBase._load_attr\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_load_attr\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m   1789\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m.pop()\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     result = \u001b[43mBuiltinVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstantVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43margval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m     \u001b[38;5;28mself\u001b[39m.push(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1004\u001b[39m, in \u001b[36mBuiltinVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handler:\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28mself\u001b[39m.call_function_handler_cache[key] = handler = \u001b[38;5;28mself\u001b[39m._make_handler(\n\u001b[32m   1002\u001b[39m         \u001b[38;5;28mself\u001b[39m.fn, [\u001b[38;5;28mtype\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;28mbool\u001b[39m(kwargs)\n\u001b[32m   1003\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:717\u001b[39m, in \u001b[36mBuiltinVariable._make_handler.<locals>.<lambda>\u001b[39m\u001b[34m(tx, args, kwargs)\u001b[39m\n\u001b[32m    714\u001b[39m handlers = []\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28missubclass\u001b[39m(t, LazyVariableTracker) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m arg_types):\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m tx, args, kwargs: \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.isclass(fn) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(fn, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcreate_exception_class_object\u001b[39m(\n\u001b[32m    724\u001b[39m         tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs\n\u001b[32m    725\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1004\u001b[39m, in \u001b[36mBuiltinVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handler:\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28mself\u001b[39m.call_function_handler_cache[key] = handler = \u001b[38;5;28mself\u001b[39m._make_handler(\n\u001b[32m   1002\u001b[39m         \u001b[38;5;28mself\u001b[39m.fn, [\u001b[38;5;28mtype\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;28mbool\u001b[39m(kwargs)\n\u001b[32m   1003\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:852\u001b[39m, in \u001b[36mBuiltinVariable._make_handler.<locals>.builtin_dispatch\u001b[39m\u001b[34m(tx, args, kwargs)\u001b[39m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mbuiltin_dispatch\u001b[39m(tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs):\n\u001b[32m    851\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m         rv = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m rv:\n\u001b[32m    854\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:772\u001b[39m, in \u001b[36mBuiltinVariable._make_handler.<locals>.call_self_handler\u001b[39m\u001b[34m(tx, args, kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcall_self_handler\u001b[39m(tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs):\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m         result = \u001b[43mself_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    773\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    774\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1704\u001b[39m, in \u001b[36mBuiltinVariable.call_getattr\u001b[39m\u001b[34m(self, tx, obj, name_var, default)\u001b[39m\n\u001b[32m   1692\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1693\u001b[39m     obj,\n\u001b[32m   1694\u001b[39m     (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1701\u001b[39m     ),\n\u001b[32m   1702\u001b[39m ):\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvar_getattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m   1706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m GetAttrVariable(obj, name, source=source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:328\u001b[39m, in \u001b[36mVariableTracker.var_getattr\u001b[39m\u001b[34m(self, tx, name)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mvar_getattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    327\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"getattr(self, name) returning a new variable\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconst_getattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m variables.ConstantVariable.is_literal(value):\n\u001b[32m    330\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:113\u001b[39m, in \u001b[36mConstantVariable.const_getattr\u001b[39m\u001b[34m(self, tx, name)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mconst_getattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     member = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(member):\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mInternalTorchDynamoError\u001b[39m: AttributeError: 'NoneType' object has no attribute 'to'\n\nfrom user code:\n   File \"/home/unsloth-training/unsloth_compiled_cache/UnslothGRPOTrainer.py\", line 221, in grpo_compute_loss_slow\n    old_logits = old_logits.to(torch.float32)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºè®­ç»ƒå™¨ï¼Œå¹¶ä¸”ä½¿ç”¨ä¸Šé¢ç»™å‡ºçš„ reward function\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        match_format_exactly,\n",
    "        match_format_approximately,\n",
    "        check_answer,\n",
    "        check_numbers,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = final_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeaca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# import json\n",
    "\n",
    "# # è®¾ç½®å¯è§†åŒ–é£æ ¼ï¼Œæé«˜å›¾è¡¨ç¾è§‚åº¦\n",
    "# plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# sns.set_palette('viridis')\n",
    "# plt.rcParams['figure.figsize'] = (12, 6)\n",
    "# plt.rcParams['figure.dpi'] = 100\n",
    "# plt.rcParams['font.size'] = 12\n",
    "\n",
    "# def extract_rewards_from_trainer(trainer):\n",
    "#     \"\"\"ä»GRPOTrainerå¯¹è±¡ä¸­æå–å¥–åŠ±æ•°æ®\n",
    "    \n",
    "#     å‚æ•°:\n",
    "#         trainer: GRPOTrainerå¯¹è±¡\n",
    "#     è¿”å›:\n",
    "#         pd.DataFrame: åŒ…å«æ­¥éª¤å’Œå¯¹åº”å¥–åŠ±çš„æ•°æ®æ¡†\n",
    "#     \"\"\"\n",
    "#     if not hasattr(trainer, 'state') or not hasattr(trainer.state, 'log_history'):\n",
    "#         print(\"è®­ç»ƒå™¨æ²¡æœ‰å¯ç”¨çš„æ—¥å¿—å†å²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbbf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜å›¾!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "\n",
    "# è®¾ç½®Seabornæ ·å¼ä»¥è·å¾—æ›´å¥½çœ‹çš„å›¾è¡¨\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "def extract_rewards_from_log(log_path):\n",
    "    \"\"\"ä»è®­ç»ƒæ—¥å¿—æ–‡ä»¶ä¸­æå–å¥–åŠ±æ•°æ®\n",
    "    \n",
    "    å‚æ•°:\n",
    "        log_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„\n",
    "        \n",
    "    è¿”å›:\n",
    "        åŒ…å«æ­¥éª¤å’Œå¯¹åº”å¥–åŠ±çš„pandas DataFrame\n",
    "    \"\"\"\n",
    "    # å­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "    data = defaultdict(list)\n",
    "    step_pattern = re.compile(r'Step\\s+(\\d+)')\n",
    "    reward_pattern = re.compile(r'Reward_(\\d+):\\s+([-\\d.]+)')\n",
    "    mean_reward_pattern = re.compile(r'Mean Reward:\\s+([-\\d.]+)')\n",
    "    \n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"æ—¥å¿—æ–‡ä»¶ {log_path} ä¸å­˜åœ¨!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # æå–æ­¥éª¤\n",
    "            step_match = step_pattern.search(line)\n",
    "            if step_match:\n",
    "                current_step = int(step_match.group(1))\n",
    "                data['step'].append(current_step)\n",
    "                \n",
    "                # æå–å„ä¸ªå¥–åŠ±å‡½æ•°çš„å€¼\n",
    "                rewards = reward_pattern.findall(line)\n",
    "                for idx, value in rewards:\n",
    "                    data[f'reward_{idx}'].append(float(value))\n",
    "                \n",
    "                # æå–å¹³å‡å¥–åŠ±\n",
    "                mean_match = mean_reward_pattern.search(line)\n",
    "                if mean_match:\n",
    "                    data['mean_reward'].append(float(mean_match.group(1)))\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_rewards_from_trainer(trainer):\n",
    "    \"\"\"ä»trainerå¯¹è±¡ä¸­ç›´æ¥æå–å¥–åŠ±æ•°æ®\n",
    "    \n",
    "    å‚æ•°:\n",
    "        trainer: GRPOTrainerå¯¹è±¡\n",
    "        \n",
    "    è¿”å›:\n",
    "        åŒ…å«æ­¥éª¤å’Œå¯¹åº”å¥–åŠ±çš„pandas DataFrame\n",
    "    \"\"\"\n",
    "    if hasattr(trainer, 'state') and hasattr(trainer.state, 'log_history'):\n",
    "        data = defaultdict(list)\n",
    "        for entry in trainer.state.log_history:\n",
    "            if 'step' in entry:\n",
    "                data['step'].append(entry['step'])\n",
    "                \n",
    "                # æå–å„ä¸ªå¥–åŠ±\n",
    "                for key, value in entry.items():\n",
    "                    if key.startswith('reward_'):\n",
    "                        data[key].append(value)\n",
    "                \n",
    "                # æå–å¹³å‡å¥–åŠ±\n",
    "                if 'mean_reward' in entry:\n",
    "                    data['mean_reward'].append(entry['mean_reward'])\n",
    "                \n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        print(\"è®­ç»ƒå™¨æ²¡æœ‰æ—¥å¿—å†å²æˆ–è€…ç»“æ„ä¸ç¬¦åˆé¢„æœŸ!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def plot_rewards(data, title=\"GRPOè®­ç»ƒå¥–åŠ±æ›²çº¿\", save_path=None, moving_avg_window=5):\n",
    "    \"\"\"ç»˜åˆ¶å¥–åŠ±æŠ˜çº¿å›¾\n",
    "    \n",
    "    å‚æ•°:\n",
    "        data: åŒ…å«å¥–åŠ±æ•°æ®çš„DataFrame\n",
    "        title: å›¾è¡¨æ ‡é¢˜\n",
    "        save_path: ä¿å­˜å›¾è¡¨çš„è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™æ˜¾ç¤ºå›¾è¡¨\n",
    "        moving_avg_window: ç§»åŠ¨å¹³å‡çª—å£å¤§å°\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        print(\"æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜å›¾!\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # å®šä¹‰ä¸€ç»„ä¸“ä¸šçš„é¢œè‰²\n",
    "    colors = sns.color_palette('viridis', n_colors=len(data.columns)-1)\n",
    "    \n",
    "    # ç»˜åˆ¶æ¯ä¸ªå¥–åŠ±å‡½æ•°çš„æ›²çº¿\n",
    "    for i, col in enumerate([col for col in data.columns if col != 'step']):\n",
    "        # åŸå§‹æ•°æ®ç‚¹ï¼ˆé€æ˜åº¦é™ä½ï¼‰\n",
    "        ax.plot(data['step'], data[col], alpha=0.3, color=colors[i], label=f\"{col} (raw)\")\n",
    "        \n",
    "        # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿\n",
    "        if len(data) >= moving_avg_window:\n",
    "            moving_avg = data[col].rolling(window=moving_avg_window).mean()\n",
    "            ax.plot(data['step'], moving_avg, linewidth=2, color=colors[i], label=f\"{col} ({moving_avg_window}-point avg)\")\n",
    "    \n",
    "    # æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Training Steps', fontsize=14)\n",
    "    ax.set_ylabel('Reward', fontsize=14)\n",
    "    \n",
    "    # æ·»åŠ ç½‘æ ¼çº¿å’Œå›¾ä¾‹\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(loc='best', fontsize=12)\n",
    "    \n",
    "    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯\n",
    "    if 'mean_reward' in data.columns:\n",
    "        final_mean = data['mean_reward'].iloc[-1]\n",
    "        max_mean = data['mean_reward'].max()\n",
    "        min_mean = data['mean_reward'].min()\n",
    "        stats_text = f\"Final mean reward: {final_mean:.4f}\\nMax mean reward: {max_mean:.4f}\\nMin mean reward: {min_mean:.4f}\"\n",
    "        plt.figtext(0.02, 0.02, stats_text, fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾è¡¨\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"å›¾è¡¨å·²ä¿å­˜åˆ° {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# ç¤ºä¾‹ç”¨æ³•\n",
    "def visualize_rewards(trainer=None, log_file=None, output_path=None):\n",
    "    \"\"\"å¯è§†åŒ–è®­ç»ƒå¥–åŠ±\n",
    "    \n",
    "    å‚æ•°:\n",
    "        trainer: GRPOTrainerå¯¹è±¡ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥ä»è®­ç»ƒå™¨ä¸­æå–æ•°æ®\n",
    "        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœtrainerä¸å¯ç”¨åˆ™ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–æ•°æ®\n",
    "        output_path: å›¾è¡¨ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„'reward_plot.png'\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = 'reward_plot.png'\n",
    "    \n",
    "    if trainer is not None:\n",
    "        data = extract_rewards_from_trainer(trainer)\n",
    "    elif log_file is not None:\n",
    "        data = extract_rewards_from_log(log_file)\n",
    "    else:\n",
    "        print(\"è¯·æä¾›trainerå¯¹è±¡æˆ–æ—¥å¿—æ–‡ä»¶è·¯å¾„!\")\n",
    "        return\n",
    "    \n",
    "    plot_rewards(data, save_path=output_path)\n",
    "    \n",
    "    # è¾“å‡ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯\n",
    "    if not data.empty and 'mean_reward' in data.columns:\n",
    "        print(\"\\n--- å¥–åŠ±ç»Ÿè®¡ä¿¡æ¯ ---\")\n",
    "        print(f\"æœ€ç»ˆå¹³å‡å¥–åŠ±: {data['mean_reward'].iloc[-1]:.4f}\")\n",
    "        print(f\"æœ€å¤§å¹³å‡å¥–åŠ±: {data['mean_reward'].max():.4f}\")\n",
    "        print(f\"æœ€å°å¹³å‡å¥–åŠ±: {data['mean_reward'].min():.4f}\")\n",
    "        \n",
    "        # è®¡ç®—å¥–åŠ±å¢é•¿ç‡\n",
    "        if len(data) > 1:\n",
    "            first_reward = data['mean_reward'].iloc[0]\n",
    "            last_reward = data['mean_reward'].iloc[-1]\n",
    "            growth = ((last_reward - first_reward) / abs(first_reward)) * 100 if first_reward != 0 else float('inf')\n",
    "            print(f\"å¥–åŠ±å¢é•¿ç‡: {growth:.2f}%\")\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "# 1. ä½¿ç”¨è®­ç»ƒå™¨å¯¹è±¡\n",
    "# visualize_rewards(trainer=trainer)\n",
    "\n",
    "# 2. æˆ–è€…ä½¿ç”¨æ—¥å¿—æ–‡ä»¶\n",
    "visualize_rewards(log_file=\"./outputs_gemma-3_grpo_lora/opt_gemm3_2.log\")\n",
    "\n",
    "# ä»è®­ç»ƒåç›´æ¥å¯è§†åŒ–\n",
    "# åœ¨è®­ç»ƒåè°ƒç”¨ä»¥ä¸‹ä»£ç å³å¯ç›´æ¥å¯è§†åŒ–\n",
    "# visualize_rewards(trainer=trainer, output_path=\"reward_trends.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95da640",
   "metadata": {},
   "source": [
    "### æ¨¡å‹æµ‹è¯•\n",
    "#### é»˜è®¤æ¨¡å‹æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b72b37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_working_out>\n",
      "Let $N$ be the number of people in the group, so $N = 18$.\n",
      "Each person gets 3 slices of pizza.\n",
      "The total number of slices needed is $18 \\times 3 = 54$ slices.\n",
      "Each pizza has 9 slices.\n",
      "Let $P$ be the number of pizzas they need to order.\n",
      "The total number of slices from $P$ pizzas is $9P$.\n",
      "We need $9P \\ge 54$.\n",
      "Dividing both sides by 9, we get $P \\ge \\frac{54}{9} = 6$.\n",
      "Since they need to order a whole number of pizzas, they need to order at least 6 pizzas.\n",
      "Therefore, they should order 6 pizzas.\n",
      "<end_working_out>\n",
      "<SOLUTION>6\n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": \"There is a group of 18 people who are ordering pizza. If each person gets 3 slices and each pizza has 9 slices, how many pizzas should they order? \"},\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    tokenize = False,\n",
    ")\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 1024, # Increase for longer outputs!\n",
    "    # Recommended Gemma-3 settings!\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½åŸå§‹æ¨¡å‹ï¼ˆä¸åŒ…å«å¾®è°ƒï¼‰\n",
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "# å®šä¹‰ç›¸åŒçš„å‚æ•°\n",
    "max_seq_length = 1024\n",
    "\n",
    "# é‡æ–°åŠ è½½åŸå§‹æ¨¡å‹ï¼ˆä¸åº”ç”¨LoRAæƒé‡ï¼‰\n",
    "original_model, original_tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"./models/gemma-3-1b-it\",  # ä½¿ç”¨åŸå§‹æ¨¡å‹è·¯å¾„\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = False,\n",
    ")\n",
    "\n",
    "# æµ‹è¯•é—®é¢˜\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},  # ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ç³»ç»Ÿæç¤ºè¯\n",
    "    {\"role\": \"user\", \"content\": \"What is the sqrt of 101?\"},  # ä½¿ç”¨åŒæ ·çš„æµ‹è¯•é—®é¢˜ä»¥ä¾¿æ¯”è¾ƒ\n",
    "]\n",
    "\n",
    "# å‡†å¤‡è¾“å…¥\n",
    "test_text = original_tokenizer.apply_chat_template(\n",
    "    test_messages,\n",
    "    add_generation_prompt = True,\n",
    "    tokenize = False,\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨TextStreamerç›´æ¥æŸ¥çœ‹è¾“å‡º\n",
    "from transformers import TextStreamer\n",
    "print(\"\\nåŸå§‹æ¨¡å‹è¾“å‡ºï¼š\")\n",
    "_ = original_model.generate(\n",
    "    **original_tokenizer(test_text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 1024,\n",
    "    temperature = 0.8,  # ä½¿ç”¨ä¸å¾®è°ƒæ¨¡å‹ç›¸åŒçš„æ¸©åº¦\n",
    "    top_p = 0.95,\n",
    "    top_k = 64,\n",
    "    streamer = TextStreamer(original_tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426953b",
   "metadata": {},
   "source": [
    "#### finetuning æ¨¡å‹æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfea2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ Lora\n",
    "model.save_lora(\"grpo_saved_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833dc17",
   "metadata": {},
   "source": [
    "#### ä¿å­˜ Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855619d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma-3/tokenizer_config.json',\n",
       " 'gemma-3/special_tokens_map.json',\n",
       " 'gemma-3/tokenizer.model',\n",
       " 'gemma-3/added_tokens.json',\n",
       " 'gemma-3/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"gemma-3\")  # Local saving\n",
    "tokenizer.save_pretrained(\"gemma-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "790cbde8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:125\u001b[0m, in \u001b[0;36mHfFileSystem._repo_and_revision_exist\u001b[0;34m(self, repo_type, repo_id, revision)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api\u001b[38;5;241m.\u001b[39mrepo_info(\n\u001b[1;32m    126\u001b[0m         repo_id, revision\u001b[38;5;241m=\u001b[39mrevision, repo_type\u001b[38;5;241m=\u001b[39mrepo_type, timeout\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mHF_HUB_ETAG_TIMEOUT\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (RepositoryNotFoundError, HFValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './models'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:545\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mList the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:216\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m repo_and_revision_exist:\n\u001b[0;32m--> 216\u001b[0m         _raise_file_not_found(path, err)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:1136\u001b[0m, in \u001b[0;36m_raise_file_not_found\u001b[0;34m(path, err)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (invalid repository id)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ./models/gemma-3-1b-it (invalid repository id)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \u001b[38;5;66;03m# Change to True to save finetune!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_pretrained_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma-3-finetune\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2357\u001b[0m, in \u001b[0;36munsloth_generic_save_pretrained_merged\u001b[0;34m(self, save_directory, tokenizer, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2355\u001b[0m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2357\u001b[0m unsloth_generic_save(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m   2359\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2304\u001b[0m, in \u001b[0;36munsloth_generic_save\u001b[0;34m(model, tokenizer, save_directory, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, use_temp_dir, commit_message, private, create_pr, revision, commit_description, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munsloth_generic_save\u001b[39m(\n\u001b[1;32m   2276\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     maximum_memory_usage : \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m   2302\u001b[0m ):\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m push_to_hub: token \u001b[38;5;241m=\u001b[39m get_token()\n\u001b[0;32m-> 2304\u001b[0m     merge_and_overwrite_lora(\n\u001b[1;32m   2305\u001b[0m         get_model_name,\n\u001b[1;32m   2306\u001b[0m         model                \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m   2307\u001b[0m         tokenizer            \u001b[38;5;241m=\u001b[39m tokenizer,\n\u001b[1;32m   2308\u001b[0m         save_directory       \u001b[38;5;241m=\u001b[39m save_directory,\n\u001b[1;32m   2309\u001b[0m         push_to_hub          \u001b[38;5;241m=\u001b[39m push_to_hub,\n\u001b[1;32m   2310\u001b[0m         private              \u001b[38;5;241m=\u001b[39m private,\n\u001b[1;32m   2311\u001b[0m         token                \u001b[38;5;241m=\u001b[39m token,\n\u001b[1;32m   2312\u001b[0m         output_dtype         \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2313\u001b[0m         low_disk_space_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2314\u001b[0m         use_temp_file        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2315\u001b[0m     )\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:549\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    547\u001b[0m     original_model_id \u001b[38;5;241m=\u001b[39m get_original_model_id(model_name)\n\u001b[1;32m    548\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m original_model_id\n\u001b[0;32m--> 549\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    551\u001b[0m safetensors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    552\u001b[0m max_size_in_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mls\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, detail: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, refresh: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    List the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m        dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m     path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[1;32m    370\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: detail, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:172\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    169\u001b[0m         revision \u001b[38;5;241m=\u001b[39m revision_in_path\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revision\n\u001b[0;32m--> 172\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# can't list repositories at root\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to repositories lists is not implemented.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/fsspec/spec.py:198\u001b[0m, in \u001b[0;36mAbstractFileSystem._strip_protocol\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    196\u001b[0m protos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m protocol \u001b[38;5;129;01min\u001b[39;00m protos:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    199\u001b[0m         path \u001b[38;5;241m=\u001b[39m path[\u001b[38;5;28mlen\u001b[39m(protocol) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m :]\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "if True: # Change to True to save finetune!\n",
    "    model.save_pretrained_merged(\"gemma-3-finetune\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a0885",
   "metadata": {},
   "source": [
    "### ä¿å­˜ä¸ºå®Œæ•´æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27072ac2",
   "metadata": {},
   "source": [
    "##### ä¿å­˜ä¸º bf16 æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4381df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:125\u001b[0m, in \u001b[0;36mHfFileSystem._repo_and_revision_exist\u001b[0;34m(self, repo_type, repo_id, revision)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api\u001b[38;5;241m.\u001b[39mrepo_info(\n\u001b[1;32m    126\u001b[0m         repo_id, revision\u001b[38;5;241m=\u001b[39mrevision, repo_type\u001b[38;5;241m=\u001b[39mrepo_type, timeout\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mHF_HUB_ETAG_TIMEOUT\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (RepositoryNotFoundError, HFValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './models'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:545\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mList the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:216\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m repo_and_revision_exist:\n\u001b[0;32m--> 216\u001b[0m         _raise_file_not_found(path, err)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:1136\u001b[0m, in \u001b[0;36m_raise_file_not_found\u001b[0;34m(path, err)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (invalid repository id)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ./models/gemma-3-1b-it (invalid repository id)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge to 16bit\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: model\u001b[38;5;241m.\u001b[39msave_pretrained_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, save_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_16bit\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: model\u001b[38;5;241m.\u001b[39mpush_to_hub_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf/model\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, save_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_16bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Merge to 4bit\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2357\u001b[0m, in \u001b[0;36munsloth_generic_save_pretrained_merged\u001b[0;34m(self, save_directory, tokenizer, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2355\u001b[0m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2357\u001b[0m unsloth_generic_save(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m   2359\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2304\u001b[0m, in \u001b[0;36munsloth_generic_save\u001b[0;34m(model, tokenizer, save_directory, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, use_temp_dir, commit_message, private, create_pr, revision, commit_description, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munsloth_generic_save\u001b[39m(\n\u001b[1;32m   2276\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     maximum_memory_usage : \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m   2302\u001b[0m ):\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m push_to_hub: token \u001b[38;5;241m=\u001b[39m get_token()\n\u001b[0;32m-> 2304\u001b[0m     merge_and_overwrite_lora(\n\u001b[1;32m   2305\u001b[0m         get_model_name,\n\u001b[1;32m   2306\u001b[0m         model                \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m   2307\u001b[0m         tokenizer            \u001b[38;5;241m=\u001b[39m tokenizer,\n\u001b[1;32m   2308\u001b[0m         save_directory       \u001b[38;5;241m=\u001b[39m save_directory,\n\u001b[1;32m   2309\u001b[0m         push_to_hub          \u001b[38;5;241m=\u001b[39m push_to_hub,\n\u001b[1;32m   2310\u001b[0m         private              \u001b[38;5;241m=\u001b[39m private,\n\u001b[1;32m   2311\u001b[0m         token                \u001b[38;5;241m=\u001b[39m token,\n\u001b[1;32m   2312\u001b[0m         output_dtype         \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2313\u001b[0m         low_disk_space_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2314\u001b[0m         use_temp_file        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2315\u001b[0m     )\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:549\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    547\u001b[0m     original_model_id \u001b[38;5;241m=\u001b[39m get_original_model_id(model_name)\n\u001b[1;32m    548\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m original_model_id\n\u001b[0;32m--> 549\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    551\u001b[0m safetensors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    552\u001b[0m max_size_in_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mls\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, detail: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, refresh: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    List the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m        dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m     path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[1;32m    370\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: detail, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:172\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    169\u001b[0m         revision \u001b[38;5;241m=\u001b[39m revision_in_path\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revision\n\u001b[0;32m--> 172\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# can't list repositories at root\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to repositories lists is not implemented.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/fsspec/spec.py:198\u001b[0m, in \u001b[0;36mAbstractFileSystem._strip_protocol\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    196\u001b[0m protos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m protocol \u001b[38;5;129;01min\u001b[39;00m protos:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    199\u001b[0m         path \u001b[38;5;241m=\u001b[39m path[\u001b[38;5;28mlen\u001b[39m(protocol) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m :]\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "# Merge to 16bit\n",
    "if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "if True: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# Merge to 4bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# Just LoRA adapters\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Change to True to upload finetune\n",
    "    model.push_to_hub_merged(\n",
    "        \"HF_ACCOUNT/gemma-3-finetune\", tokenizer,\n",
    "        token = \"hf_...\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ä¸º GGUF æ ¼å¼\n",
    "# if False:\n",
    "#     model.save_pretrained_gguf(\n",
    "#         \"gemma-3-finetune\",\n",
    "#         quantization_type = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a89623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False: # Change to True to upload GGUF\n",
    "#     model.push_to_hub_gguf(\n",
    "#         \"gemma-3-finetune\",\n",
    "#         quantization_type = \"Q8_0\", # Only Q8_0, BF16, F16 supported\n",
    "#         repo_id = \"HF_ACCOUNT/gemma-finetune-gguf\",\n",
    "#         token = \"hf_...\",\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
