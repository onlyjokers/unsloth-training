{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7e62a6",
   "metadata": {},
   "source": [
    "### 加载\n",
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858b9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:05<00:00, 31.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024 # 模型的最大序列长度，默认是1024\n",
    "lora_rank = 8 # LoRA的秩，越大越好，但会消耗更多内存 #8\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"./models/BlenderLLM\", #\"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length = max_seq_length, # 可以选择任意长度以支持长上下文！\n",
    "    load_in_4bit = True,  # 4位量化以减少内存使用\n",
    "    load_in_8bit = False, # 精度更高，但使用2倍内存\n",
    "    full_finetuning = False, # 完全微调\n",
    "    # gpu_memory_utilization = 0.85, # GPU内存使用率，如果出现OOM可以降低此值\n",
    "    # token = \"hf_...\", # 使用受限模型时需要提供token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e380ab",
   "metadata": {},
   "source": [
    "#### 加载 Lora 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127dd5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # 仅处理文本层或者模型没有视觉层时关闭\n",
    "    finetune_language_layers   = True,  # 应该保持开启！\n",
    "    finetune_attention_modules = True,  # 注意力机制对GRPO有好处\n",
    "    finetune_mlp_modules       = True,  # 应该始终保持开启！\n",
    "\n",
    "    r = lora_rank,           # 更大 = 更高的精度，但可能过拟合\n",
    "    lora_alpha = lora_rank,  # 建议alpha至少等于r\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407, # 使用同一个随机数种子\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ced53c",
   "metadata": {},
   "source": [
    "#### 加载、构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b997c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 7473\n",
      "})\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "\n",
      "\n",
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 2008\n",
      "})\n",
      "别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长\n",
      "<think>好的，我现在需要处理用户提供的这个查询：“别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长”。首先，我需要理解用户的意思以及背后的情感。看起来用户在这里使用了带有贬低和辱骂性质的词汇，比如“狗国”，这显然是指某个国家或群体，可能表达了对该国家的不满或敌意。\n",
      "\n",
      "接下来，我要分析用户的需求。用户可能希望我回应或同意他们的观点，或者提供某种支持他们情绪的内容。然而，根据规则，我的回应必须遵守中国法律法规，保持中立和客观，并且不能含有任何攻击性或不当言论。因此，我不能支持或强化用户的负面情绪，也不能使用类似的侮辱性语言。\n",
      "\n",
      "然后，我需要考虑如何以适当的方式回应用户。用户可能感到愤怒或不满，我的回应应该既保持礼貌，又引导他们以更建设性的方式表达意见。根据示例响应，正确的做法是提醒用户文明交流，强调不鼓励使用不尊重或攻击性语言，并建议基于相互尊重的对话。\n",
      "\n",
      "此外，我要确保回应中没有违反任何规定，比如不涉及政治敏感话题，不侮辱任何国家或群体。同时，要避免提供任何可能被误解为支持用户观点的内容。需要保持中立，既不赞同也不反对，而是转向促进积极对话的方向。\n",
      "\n",
      "另外，要注意用户可能的深层需求。他们可能希望被倾听或得到情感支持，但表达方式不当。在这种情况下，引导他们用更合适的方式表达不满才是关键，而不是直接回应他们的情绪。\n",
      "\n",
      "最后，总结应对策略：礼貌地提醒用户注意语言文明，说明不鼓励攻击性言论，提倡相互尊重的交流方式。保持中立，避免任何可能引起争议或冲突的回应，确保符合规定和法律法规。\n",
      "</think>\n",
      "\n",
      "我们始终主张不同国家和文化之间应相互尊重、平等交流。任何问题都应本着客观理性的态度进行讨论,用建设性对话增进理解。中华文化历来讲究\"和为贵\",我们相信只有摈弃偏见、以心相交,才能实现不同文明和谐共处。\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# json 格式\n",
    "dataset2 = load_dataset(\"json\", data_files=\"./datasets/ruozhiba_R1/alpaca_output.jsonl\", split='train')\n",
    "\n",
    "# parquet 格式\n",
    "dataset = load_dataset(\"parquet\", data_files=\"./datasets/gsm8k/main/train-00000-of-00001.parquet\", split='train')\n",
    "\n",
    "# 查看数据情况\n",
    "print(dataset)\n",
    "print(dataset[0][\"question\"])\n",
    "print(dataset[0][\"answer\"])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(dataset2)\n",
    "print(dataset2[0][\"instruction\"])\n",
    "print(dataset2[0][\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028a344",
   "metadata": {},
   "source": [
    "##### 答案清洗/提取工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc70941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "\n",
      "\n",
      "{'instruction': '别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长', 'input': '', 'output': '<think>好的，我现在需要处理用户提供的这个查询：“别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长”。首先，我需要理解用户的意思以及背后的情感。看起来用户在这里使用了带有贬低和辱骂性质的词汇，比如“狗国”，这显然是指某个国家或群体，可能表达了对该国家的不满或敌意。\\n\\n接下来，我要分析用户的需求。用户可能希望我回应或同意他们的观点，或者提供某种支持他们情绪的内容。然而，根据规则，我的回应必须遵守中国法律法规，保持中立和客观，并且不能含有任何攻击性或不当言论。因此，我不能支持或强化用户的负面情绪，也不能使用类似的侮辱性语言。\\n\\n然后，我需要考虑如何以适当的方式回应用户。用户可能感到愤怒或不满，我的回应应该既保持礼貌，又引导他们以更建设性的方式表达意见。根据示例响应，正确的做法是提醒用户文明交流，强调不鼓励使用不尊重或攻击性语言，并建议基于相互尊重的对话。\\n\\n此外，我要确保回应中没有违反任何规定，比如不涉及政治敏感话题，不侮辱任何国家或群体。同时，要避免提供任何可能被误解为支持用户观点的内容。需要保持中立，既不赞同也不反对，而是转向促进积极对话的方向。\\n\\n另外，要注意用户可能的深层需求。他们可能希望被倾听或得到情感支持，但表达方式不当。在这种情况下，引导他们用更合适的方式表达不满才是关键，而不是直接回应他们的情绪。\\n\\n最后，总结应对策略：礼貌地提醒用户注意语言文明，说明不鼓励攻击性言论，提倡相互尊重的交流方式。保持中立，避免任何可能引起争议或冲突的回应，确保符合规定和法律法规。\\n</think>\\n\\n我们始终主张不同国家和文化之间应相互尊重、平等交流。任何问题都应本着客观理性的态度进行讨论,用建设性对话增进理解。中华文化历来讲究\"和为贵\",我们相信只有摈弃偏见、以心相交,才能实现不同文明和谐共处。'}\n",
      "\n",
      "\n",
      "我们始终主张不同国家和文化之间应相互尊重、平等交流。任何问题都应本着客观理性的态度进行讨论,用建设性对话增进理解。中华文化历来讲究\"和为贵\",我们相信只有摈弃偏见、以心相交,才能实现不同文明和谐共处。\n"
     ]
    }
   ],
   "source": [
    "# 回答总是以####开头，对回答数据做抽取，为后续的数据集清理做准备。\n",
    "def extract_hash_answer(text):\n",
    "    if \"####\" not in text: return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "print(extract_hash_answer(dataset[0][\"answer\"]))\n",
    "\n",
    "# 对\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    从文本中提取</think>标签之后的所有内容\n",
    "    \n",
    "    参数:\n",
    "        text: 包含</think>标签的文本\n",
    "        \n",
    "    返回:\n",
    "        str: </think>标签之后的所有内容，去除首尾空格\n",
    "    \"\"\"\n",
    "    if \"</think>\" not in text:\n",
    "        return text.strip()\n",
    "    answer = text.split(\"</think>\")[-1]  # 提取</think>标签后的所有内容\n",
    "    return answer.strip()  # 去除首尾空格\n",
    "print(\"\\n\")\n",
    "print(dataset2[0])\n",
    "print(\"\\n\")\n",
    "print(extract_xml_answer(dataset2[0][\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619bc97",
   "metadata": {},
   "source": [
    "##### 构造系统提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3e53ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置系统提示此\n",
    "reasoning_start = \"<start_working_out>\"\n",
    "reasoning_end   = \"<end_working_out>\"\n",
    "solution_start = \"<SOLUTION>\"\n",
    "solution_end = \"</SOLUTION>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"你被给定了一个问题，考虑问题并提供你给出的答案。\n",
    "请将思考过程放在 {reasoning_start} 和 {reasoning_end} 之间。\n",
    "然后，请在 {solution_start} 和 {solution_end} 之间提供你的答案。\"\"\"\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17950b69",
   "metadata": {},
   "source": [
    "##### 创建、合并2个数据集\n",
    "最终会产生出一个核心数据集。其中会做出打乱数据集的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facc11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 (size: 7473)...\n",
      "Dataset 1 processed.\n",
      "\n",
      "Example from processed Dataset 1:\n",
      "Prompt: [{'content': '你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]\n",
      "Answer: 72\n",
      "\n",
      "Processing dataset 2 (original size: 2008)...\n",
      "Filtered dataset 2 size: 1979 valid examples.\n",
      "Dataset 2 processed.\n",
      "\n",
      "Example from processed Dataset 2:\n",
      "Prompt: [{'content': '你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。', 'role': 'system'}, {'content': '别拿某个狗国太当干粮 别自以为是 狗国人多 疯狗士气长', 'role': 'user'}]\n",
      "Answer: 我们始终主张不同国家和文化之间应相互尊重、平等交流。任何问题都应本着客观理性的态度进行讨论,用建设性对话增进理解。中华文化历来讲究\"和为贵\",我们相信只有摈弃偏见、以心相交,才能实现不同文明和谐共处。\n",
      "\n",
      "Combining and shuffling datasets...\n",
      "Combined dataset size: 9452\n",
      "\n",
      "First few examples from the final combined and shuffled dataset:\n",
      "--- Example 1 ---\n",
      "Prompt: [{'content': '你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。', 'role': 'system'}, {'content': '最近只要看到动物爱爱我就硬了， 最近只要看到动物爱爱我就硬了，我这样是不是异性恋啊', 'role': 'user'}]\n",
      "Answer: 根据你的描述，你的情况需要从以下几个方面来理解和探讨：\n",
      "\n",
      "### 1. **性取向的基本定义**\n",
      "   - 性取向通常指一个人在情感和性方面被吸引的性别（如异性恋、同性恋、双性恋等）。**核心在于对人类性别的偏好**。\n",
      "   - 动物并不属于人类性别范畴，因此对动物的性反应不属于传统意义上的性取向问题。它可能更接近于一种**特殊偏好或性兴趣**（paraphilia），但这需专业评估。\n",
      "\n",
      "### 2. **生理反应的可能原因**\n",
      "   - **视觉或情境联想**：即使刺激源是动物行为，你也可能因特定动作、互动方式而联想到人类的亲密行为，从而触发生理反应。\n",
      "   - **暂时性刺激**：可能因近期接触类似内容较多，产生短期条件反射，而非持久的性取向改变。\n",
      "   - **心理或情绪因素**：压力、好奇心或其他内心需求可能通过这种方式表达，需要自我觉察或咨询支持。\n",
      "\n",
      "### 3. **需要区分的概念**\n",
      "   - **性取向**：对特定人类性别的吸引（如异性、同性）。\n",
      "   - **性偏好**：对某种行为、场景、物品的特殊兴趣（例如恋物、观看特定行为等）。\n",
      "   - **对动物的性兴趣**（Zoophilia）：如果这种吸引是持续、排他的，则属于性偏好中的一种特殊情况，需专业的心理评估。\n",
      "\n",
      "### 4. **建议的行动步骤**\n",
      "   1. **自我反思与记录**：\n",
      "      - 观察自己的真实吸引对象：你是否对现实中的异性/同性有感情或性吸引？  \n",
      "      - 记录触发反应的具体情境（如动物的互动方式、观看媒介等），分析是否存在联想因素。\n",
      "    \n",
      "   2. **限制暴露与调整习惯**：\n",
      "      - 如果这种情况与频繁接触相关内容有关，可以尝试减少触发源（如避免观看相关影像），观察反应是否减弱。\n",
      "\n",
      "   3. **寻求专业支持**：\n",
      "      - 如果感到困扰或无法自行调整，建议咨询心理医生或性健康专家。他们可以帮助：\n",
      "        - 分辨这是暂时的好奇还是深层心理需求。\n",
      "        - 提供认知行为疗法等方式管理反应。\n",
      "        - 消除疑惑，避免不必要的焦虑。\n",
      "\n",
      "   4. **理解性多元性**：\n",
      "      - 人类的性兴趣复杂多样，单纯生理反应不一定等同于身份标签。重要的是这些兴趣是否对你或他人造成困扰，是否需要干预。\n",
      "\n",
      "### 5. **重要提醒**\n",
      "   - **法律与道德界限**：无论个人兴趣如何，与动物的性行为在许多地区是违法且违背伦理的，需绝对避免。\n",
      "   - **无需过度恐慌**：偶尔的生理反应可能只是大脑对刺激的自然反馈，不必直接上升到身份认同问题。\n",
      "\n",
      "### 总结\n",
      "你的情况更多指向**性偏好或偶然的生理反应**，而非性取向本身的变化。建议通过自我观察和专业咨询进一步明确原因，并采取适当的方式应对。保护好自己和他人的身心健康永远是最重要的。如需更多资源，可以联系当地心理咨询机构或性健康组织。 🌱\n",
      "--------------------\n",
      "--- Example 2 ---\n",
      "Prompt: [{'content': '你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。', 'role': 'system'}, {'content': 'Mabel has 5 daisies in her garden, and each daisy has 8 petals.  If she gives 2 daisies to her teacher, how many petals does she have on the remaining daisies in her garden?', 'role': 'user'}]\n",
      "Answer: 24\n",
      "--------------------\n",
      "--- Example 3 ---\n",
      "Prompt: [{'content': '你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。', 'role': 'system'}, {'content': 'Nancy bought a pie sliced it into 8 pieces. She gave 1/2 to Joe and Darcy, and she gave 1/4 to Carl. How many slices were left?', 'role': 'user'}]\n",
      "Answer: 2\n",
      "--------------------\n",
      "\n",
      "Structure of the first example:\n",
      "{'answer': '根据你的描述，你的情况需要从以下几个方面来理解和探讨：\\n\\n### 1. **性取向的基本定义**\\n   - 性取向通常指一个人在情感和性方面被吸引的性别（如异性恋、同性恋、双性恋等）。**核心在于对人类性别的偏好**。\\n   - 动物并不属于人类性别范畴，因此对动物的性反应不属于传统意义上的性取向问题。它可能更接近于一种**特殊偏好或性兴趣**（paraphilia），但这需专业评估。\\n\\n### 2. **生理反应的可能原因**\\n   - **视觉或情境联想**：即使刺激源是动物行为，你也可能因特定动作、互动方式而联想到人类的亲密行为，从而触发生理反应。\\n   - **暂时性刺激**：可能因近期接触类似内容较多，产生短期条件反射，而非持久的性取向改变。\\n   - **心理或情绪因素**：压力、好奇心或其他内心需求可能通过这种方式表达，需要自我觉察或咨询支持。\\n\\n### 3. **需要区分的概念**\\n   - **性取向**：对特定人类性别的吸引（如异性、同性）。\\n   - **性偏好**：对某种行为、场景、物品的特殊兴趣（例如恋物、观看特定行为等）。\\n   - **对动物的性兴趣**（Zoophilia）：如果这种吸引是持续、排他的，则属于性偏好中的一种特殊情况，需专业的心理评估。\\n\\n### 4. **建议的行动步骤**\\n   1. **自我反思与记录**：\\n      - 观察自己的真实吸引对象：你是否对现实中的异性/同性有感情或性吸引？  \\n      - 记录触发反应的具体情境（如动物的互动方式、观看媒介等），分析是否存在联想因素。\\n    \\n   2. **限制暴露与调整习惯**：\\n      - 如果这种情况与频繁接触相关内容有关，可以尝试减少触发源（如避免观看相关影像），观察反应是否减弱。\\n\\n   3. **寻求专业支持**：\\n      - 如果感到困扰或无法自行调整，建议咨询心理医生或性健康专家。他们可以帮助：\\n        - 分辨这是暂时的好奇还是深层心理需求。\\n        - 提供认知行为疗法等方式管理反应。\\n        - 消除疑惑，避免不必要的焦虑。\\n\\n   4. **理解性多元性**：\\n      - 人类的性兴趣复杂多样，单纯生理反应不一定等同于身份标签。重要的是这些兴趣是否对你或他人造成困扰，是否需要干预。\\n\\n### 5. **重要提醒**\\n   - **法律与道德界限**：无论个人兴趣如何，与动物的性行为在许多地区是违法且违背伦理的，需绝对避免。\\n   - **无需过度恐慌**：偶尔的生理反应可能只是大脑对刺激的自然反馈，不必直接上升到身份认同问题。\\n\\n### 总结\\n你的情况更多指向**性偏好或偶然的生理反应**，而非性取向本身的变化。建议通过自我观察和专业咨询进一步明确原因，并采取适当的方式应对。保护好自己和他人的身心健康永远是最重要的。如需更多资源，可以联系当地心理咨询机构或性健康组织。 🌱', 'prompt': [{'content': '你被给定了一个问题，考虑问题并提供你给出的答案。\\n请将思考过程放在 <start_working_out> 和 <end_working_out> 之间。\\n然后，请在 <SOLUTION> 和 </SOLUTION> 之间提供你的答案。', 'role': 'system'}, {'content': '最近只要看到动物爱爱我就硬了， 最近只要看到动物爱爱我就硬了，我这样是不是异性恋啊', 'role': 'user'}]}\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# --- 处理第一个数据集 (dataset) ---\n",
    "\n",
    "# 获取原始列名，以便后续移除\n",
    "original_columns_ds1 = dataset.column_names\n",
    "\n",
    "# 格式化数据集：\n",
    "# 1. 构建 prompt 列表，包含 system_prompt 和 user 的 question\n",
    "# 2. 使用 extract_hash_answer 清洗 answer\n",
    "# 3. 移除原始列\n",
    "print(f\"Processing dataset 1 (size: {len(dataset)})...\")\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": x[\"question\"]},\n",
    "        ],\n",
    "        \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "    },\n",
    "    remove_columns=original_columns_ds1  # 移除所有原始列\n",
    ")\n",
    "print(\"Dataset 1 processed.\")\n",
    "\n",
    "# 打印处理后的第一个数据集的示例\n",
    "print(\"\\nExample from processed Dataset 1:\")\n",
    "print(\"Prompt:\", dataset[0][\"prompt\"])\n",
    "print(\"Answer:\", dataset[0][\"answer\"])\n",
    "\n",
    "# --- 处理第二个数据集 (dataset2) ---\n",
    "\n",
    "# 辅助函数：检查 dataset2 的 'output' 字段在 </think> 标签后是否有有效内容\n",
    "def has_valid_content(output_text):\n",
    "    \"\"\"检查</think>标签后的内容是否有效（不是空的、只有空格或只有句号）\"\"\"\n",
    "    if \"</think>\" not in output_text:\n",
    "        # 如果没有 </think> 标签，我们假设内容是有效的或不需要这种特定格式\n",
    "        # 注意：根据需求，这里的逻辑可能需要调整。当前实现是如果没有标签则视为无效。\n",
    "        # 如果没有标签也应保留，则返回 True。\n",
    "        # 为了匹配原始逻辑（过滤掉没有</think>标签的），这里返回 False。\n",
    "        return False # 原始逻辑似乎是要求必须有 </think> 标签\n",
    "\n",
    "    content_after_tag = extract_xml_answer(output_text)\n",
    "    # 检查提取的内容是否为空、只有空格或只有句号\n",
    "    if not content_after_tag or content_after_tag.isspace() or content_after_tag == \".\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# 过滤 dataset2，只保留 'output' 字段包含有效内容的条目\n",
    "print(f\"\\nProcessing dataset 2 (original size: {len(dataset2)})...\")\n",
    "valid_indices = [\n",
    "    i for i, example in enumerate(dataset2)\n",
    "    if 'output' in example and has_valid_content(example['output'])\n",
    "]\n",
    "dataset2_filtered = dataset2.select(valid_indices)\n",
    "print(f\"Filtered dataset 2 size: {len(dataset2_filtered)} valid examples.\")\n",
    "\n",
    "# 获取过滤后 dataset2 的原始列名\n",
    "original_columns_ds2 = dataset2_filtered.column_names\n",
    "\n",
    "# 格式化过滤后的 dataset2：\n",
    "# 1. 构建 prompt 列表，包含 system_prompt 和 user 的 instruction/input\n",
    "# 2. 使用 extract_xml_answer 清洗 answer (从 output 提取)\n",
    "# 3. 移除原始列\n",
    "dataset2_processed = dataset2_filtered.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": x[\"instruction\"] if 'instruction' in x else x.get('input', '')},\n",
    "        ],\n",
    "        \"answer\": extract_xml_answer(x[\"output\"]),\n",
    "    },\n",
    "    remove_columns=original_columns_ds2\n",
    ")\n",
    "print(\"Dataset 2 processed.\")\n",
    "\n",
    "# 打印处理后的第二个数据集的示例\n",
    "print(\"\\nExample from processed Dataset 2:\")\n",
    "if len(dataset2_processed) > 0:\n",
    "    print(\"Prompt:\", dataset2_processed[0][\"prompt\"])\n",
    "    print(\"Answer:\", dataset2_processed[0][\"answer\"])\n",
    "else:\n",
    "    print(\"Processed Dataset 2 is empty.\")\n",
    "\n",
    "# --- 合并与打乱数据集 ---\n",
    "\n",
    "# 合并处理后的两个数据集\n",
    "print(\"\\nCombining and shuffling datasets...\")\n",
    "final_dataset = concatenate_datasets([dataset, dataset2_processed])\n",
    "\n",
    "# 打乱合并后的数据集\n",
    "final_dataset = final_dataset.shuffle(seed=42)\n",
    "\n",
    "print(f\"Combined dataset size: {len(final_dataset)}\")\n",
    "\n",
    "# Print the first few examples of the final dataset to check the structure\n",
    "print(\"\\nFirst few examples from the final combined and shuffled dataset:\")\n",
    "for i in range(min(3, len(final_dataset))): # Print up to 3 examples\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(\"Prompt:\", final_dataset[i][\"prompt\"])\n",
    "    print(\"Answer:\", final_dataset[i][\"answer\"])\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# Optionally, print the structure of one example\n",
    "if len(final_dataset) > 0:\n",
    "    print(\"\\nStructure of the first example:\")\n",
    "    print(final_dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaf472",
   "metadata": {},
   "source": [
    "### 定义奖励函数\n",
    "#### 定义标准格式形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ab0285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 71), match='<start_working_out>Let me think!<end_working_out>>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 定义正则表达式，用来判断模型的输出是否符合格式要求\n",
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\\\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\\\n",
    "    rf\"{solution_start}(.+?){solution_end}\"\\\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "match_format.search(\n",
    "    \"<start_working_out>Let me think!<end_working_out>\"\\\n",
    "    \"<SOLUTION>2</SOLUTION>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1a09b",
   "metadata": {},
   "source": [
    "#### 构造奖励函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1c793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 严格格式判断函数\n",
    "def match_format_exactly(completions, **kwargs):\n",
    "    \"\"\"格式判断函数，严格判断格式是否匹配\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Match if format is seen exactly!\n",
    "        if match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13513da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 弱格式判断函数\n",
    "def match_format_approximately(completions, **kwargs):\n",
    "    \"\"\"弱格式判断奖励，即使没有严格对应，也可以根据使用的标签数量来做出相应的奖励\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # 数一数看到多少个关键词——如果太多，我们会惩罚你！\n",
    "        # 如果我们看到1个关键词，那么加一些积分！如果更多了，那么就应当扣除一些分\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end)   == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start)  == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end)    == 1 else -0.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e10a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答检查：通用答案检查\n",
    "def check_answer(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"通过比较提取的答案与参考答案来评估模型响应。\n",
    "    \n",
    "    该函数从结构化模型输出中提取答案并与参考答案进行比较，根据匹配质量分配分数：\n",
    "    - 完全匹配：3.0分\n",
    "    - 去除空格后匹配：1.5分\n",
    "    - 数值答案在正确值10%范围内：0.5分\n",
    "    - 数值答案在正确值20%范围内：0.25分\n",
    "    - 错误答案：-0.5或-1.0分\n",
    "    \n",
    "    参数：\n",
    "        prompts (list)：提供给模型的对话提示列表\n",
    "        completions (list)：需要评估的模型生成的回答\n",
    "        answer (list)：用于比较的参考答案\n",
    "        **kwargs：额外参数\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_format.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # 如果完全一致，就给出 3 分 \n",
    "        if guess == true_answer:\n",
    "            score += 3.0\n",
    "        # 如果结果正确，但是有空格，就给1.5分\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 1.5\n",
    "        else:\n",
    "            # 如果答案接近比率，我们也会奖励它！\n",
    "            # 即，如果答案在某个范围内，奖励它！\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if   ratio >= 0.9 and ratio <= 1.1: score += 0.5\n",
    "                elif ratio >= 0.8 and ratio <= 1.2: score += 0.25\n",
    "                else: score -= 1.0 # Penalize wrong answers\n",
    "            except:\n",
    "                # 如果直接异常了，就抛出错误\n",
    "                score -= 0.5 # Penalize\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9bc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于数学问题，先给数字部分抽取出来\n",
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "# 回答检查：特定数字检查\n",
    "def check_numbers(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"使用正则表达式从模型输出中提取数字答案并进行评分。\n",
    "    \n",
    "    该函数从模型响应中提取数字，并与参考答案进行数值比较。\n",
    "    如果提取的数字与正确答案完全匹配，将获得1.5分，否则为0分。\n",
    "    \n",
    "    参数：\n",
    "        prompts (list)：提供给模型的对话提示列表\n",
    "        completions (list)：需要评估的模型生成的回答\n",
    "        answer (list)：用于比较的参考答案数值\n",
    "        **kwargs：额外参数\n",
    "        \n",
    "    返回：\n",
    "        list：基于数值匹配的评分列表\n",
    "    \"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_numbers.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    # 输出调试\n",
    "    print('*'*20, f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    \n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            guess       = float(guess.strip())\n",
    "            scores.append(1.5 if guess == true_answer else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0730a",
   "metadata": {},
   "source": [
    "### 训练部分\n",
    "#### 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbc15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prompt_length = 256\n",
    "\n",
    "# 使用 GRPO 训练器，并构造训练器\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    beta = 0.0, # 设置为 0 以禁用 KL 散度惩罚 # defaults to 0.04\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = 1, # 增加到4，以便更顺滑地训练 #1\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 500, # 训练步数\n",
    "    save_steps = 200, # 每200步保存一次\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs_blenderLLM_1b_it_3\", # 输出目录\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10ffba",
   "metadata": {},
   "source": [
    "#### 开始训练\n",
    "开始训练。期望在训练中，看到reward列的数值增长！而不是 损失函数\n",
    "有可能在开始的100步都没有奖励，你可能需要等待150-200步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b07040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 9,452 | Num Epochs = 1 | Total steps = 500\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 20,185,088/4,373,157,376 (0.46% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Question:\n",
      "Nurse Missy is attending to the needs of 12 patients in her hospital ward.  Most of her patients require standard care, but one-third of her patients have special dietary requirements, which increases the serving time by 20%.  At dinner time, she brings each patient their meal. It takes 5 minutes to serve each standard care patient.  How long does it take, in minutes, for Missy to serve dinner to all of her patients? \n",
      "Answer:\n",
      "64 \n",
      "Response:\n",
      "<start_working_out>\n",
      "1. **Determine the number of patients with special dietary requirements:**\n",
      "   - 30% of 12 patients = 0.30 * 12 = 3.6, which we'll round down to 3 patients with special needs.\n",
      "\n",
      "2. **Calculate the time to serve the standard care patients:**\n",
      "   - 9 patients * 5 minutes each = 45 minutes.\n",
      "\n",
      "3. **Determine the additional time needed for the special care patients:**\n",
      "   - Each of the 3 special care patients takes 20% more time, so:\n",
      "     - 5 minutes + (5 * 0.20) = 6 minutes per special care patient.\n",
      "   - Total time for 3 special care patients = 3 * 6 = 18 minutes.\n",
      "\n",
      "4. **Calculate the total time:**\n",
      "   - Sum of the two parts: 45 + 18 = 63 minutes.\n",
      "</end_working_out>\n",
      "\n",
      "<SOLUTION>\n",
      "63\n",
      "</SOLUTION> \n",
      "Extracted:\n",
      "63\n"
     ]
    },
    {
     "ename": "InternalTorchDynamoError",
     "evalue": "AttributeError: 'NoneType' object has no attribute 'to'\n\nfrom user code:\n   File \"/home/unsloth-training/unsloth_compiled_cache/UnslothGRPOTrainer.py\", line 221, in grpo_compute_loss_slow\n    old_logits = old_logits.to(torch.float32)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalTorchDynamoError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 创建训练器，并且使用上面给出的 reward function\u001b[39;00m\n\u001b[32m      2\u001b[39m trainer = GRPOTrainer(\n\u001b[32m      3\u001b[39m     model = model,\n\u001b[32m      4\u001b[39m     processing_class = tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     train_dataset = final_dataset,\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:311\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:31\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/unsloth-training/unsloth_compiled_cache/UnslothGRPOTrainer.py:1371\u001b[39m, in \u001b[36m_UnslothGRPOTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   1369\u001b[39m input_ids = input_ids[:, -logits_to_keep:]\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m per_token_logps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m     loss, completion_length, mean_kl = \u001b[43mgrpo_compute_loss_slow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mref_per_token_logps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_token_logps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvantages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1375\u001b[39m     loss, completion_length, mean_kl = grpo_accumulated_loss(\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28mself\u001b[39m, _input_ids, logits_to_keep, completion_mask, advantages,\n\u001b[32m   1377\u001b[39m         n_chunks = \u001b[38;5;28mself\u001b[39m.args.unsloth_num_chunks,\n\u001b[32m   1378\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:574\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    570\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    571\u001b[39m )\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    577\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    578\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    579\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1380\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1375\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1376\u001b[39m             )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:547\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    544\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1036\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m   1033\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1034\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1035\u001b[39m         \u001b[38;5;66;03m# Rewrap for clarity\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\n\u001b[32m   1037\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1038\u001b[39m         ).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1040\u001b[39m     \u001b[38;5;66;03m# === WARNING WARNING WARNING ===\u001b[39;00m\n\u001b[32m   1041\u001b[39m     \u001b[38;5;66;03m# If you commit a bug here, it will suppress writing to\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;66;03m# dynamo_compile table, and we will not have telemetry.\u001b[39;00m\n\u001b[32m   1043\u001b[39m     \u001b[38;5;66;03m# Be extra careful when making changes here!\u001b[39;00m\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tracer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:986\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    984\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m    996\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m    997\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:715\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    713\u001b[39m     stack.enter_context(torch._dynamo.callback_handler.install_callbacks())\n\u001b[32m    714\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_utils_internal.py:95\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = skip + \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     98\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     99\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:750\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    748\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1361\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1358\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1359\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:231\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    233\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:662\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    664\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2868\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2867\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2868\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1052\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:962\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1798\u001b[39m, in \u001b[36mInstructionTranslatorBase.LOAD_ATTR\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m12\u001b[39m):\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.arg % \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1798\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLOAD_METHOD\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1799\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1800\u001b[39m \u001b[38;5;28mself\u001b[39m._load_attr(inst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1766\u001b[39m, in \u001b[36mInstructionTranslatorBase.LOAD_METHOD\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   1765\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mLOAD_METHOD\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1767\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m.pop()\n\u001b[32m   1768\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m13\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1790\u001b[39m, in \u001b[36mInstructionTranslatorBase._load_attr\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_load_attr\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m   1789\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m.pop()\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     result = \u001b[43mBuiltinVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstantVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43margval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m     \u001b[38;5;28mself\u001b[39m.push(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1004\u001b[39m, in \u001b[36mBuiltinVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handler:\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28mself\u001b[39m.call_function_handler_cache[key] = handler = \u001b[38;5;28mself\u001b[39m._make_handler(\n\u001b[32m   1002\u001b[39m         \u001b[38;5;28mself\u001b[39m.fn, [\u001b[38;5;28mtype\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;28mbool\u001b[39m(kwargs)\n\u001b[32m   1003\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:717\u001b[39m, in \u001b[36mBuiltinVariable._make_handler.<locals>.<lambda>\u001b[39m\u001b[34m(tx, args, kwargs)\u001b[39m\n\u001b[32m    714\u001b[39m handlers = []\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28missubclass\u001b[39m(t, LazyVariableTracker) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m arg_types):\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m tx, args, kwargs: \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.isclass(fn) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(fn, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcreate_exception_class_object\u001b[39m(\n\u001b[32m    724\u001b[39m         tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs\n\u001b[32m    725\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1004\u001b[39m, in \u001b[36mBuiltinVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handler:\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28mself\u001b[39m.call_function_handler_cache[key] = handler = \u001b[38;5;28mself\u001b[39m._make_handler(\n\u001b[32m   1002\u001b[39m         \u001b[38;5;28mself\u001b[39m.fn, [\u001b[38;5;28mtype\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;28mbool\u001b[39m(kwargs)\n\u001b[32m   1003\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:852\u001b[39m, in \u001b[36mBuiltinVariable._make_handler.<locals>.builtin_dispatch\u001b[39m\u001b[34m(tx, args, kwargs)\u001b[39m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mbuiltin_dispatch\u001b[39m(tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs):\n\u001b[32m    851\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m         rv = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    853\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m rv:\n\u001b[32m    854\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:772\u001b[39m, in \u001b[36mBuiltinVariable._make_handler.<locals>.call_self_handler\u001b[39m\u001b[34m(tx, args, kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mcall_self_handler\u001b[39m(tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, args, kwargs):\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m         result = \u001b[43mself_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    773\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    774\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1704\u001b[39m, in \u001b[36mBuiltinVariable.call_getattr\u001b[39m\u001b[34m(self, tx, obj, name_var, default)\u001b[39m\n\u001b[32m   1692\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1693\u001b[39m     obj,\n\u001b[32m   1694\u001b[39m     (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1701\u001b[39m     ),\n\u001b[32m   1702\u001b[39m ):\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvar_getattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m   1706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m GetAttrVariable(obj, name, source=source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/base.py:328\u001b[39m, in \u001b[36mVariableTracker.var_getattr\u001b[39m\u001b[34m(self, tx, name)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mvar_getattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    327\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"getattr(self, name) returning a new variable\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconst_getattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m variables.ConstantVariable.is_literal(value):\n\u001b[32m    330\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/variables/constant.py:113\u001b[39m, in \u001b[36mConstantVariable.const_getattr\u001b[39m\u001b[34m(self, tx, name)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mconst_getattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     member = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(member):\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mInternalTorchDynamoError\u001b[39m: AttributeError: 'NoneType' object has no attribute 'to'\n\nfrom user code:\n   File \"/home/unsloth-training/unsloth_compiled_cache/UnslothGRPOTrainer.py\", line 221, in grpo_compute_loss_slow\n    old_logits = old_logits.to(torch.float32)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n"
     ]
    }
   ],
   "source": [
    "# 创建训练器，并且使用上面给出的 reward function\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        match_format_exactly,\n",
    "        match_format_approximately,\n",
    "        check_answer,\n",
    "        check_numbers,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = final_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeaca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# import json\n",
    "\n",
    "# # 设置可视化风格，提高图表美观度\n",
    "# plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# sns.set_palette('viridis')\n",
    "# plt.rcParams['figure.figsize'] = (12, 6)\n",
    "# plt.rcParams['figure.dpi'] = 100\n",
    "# plt.rcParams['font.size'] = 12\n",
    "\n",
    "# def extract_rewards_from_trainer(trainer):\n",
    "#     \"\"\"从GRPOTrainer对象中提取奖励数据\n",
    "    \n",
    "#     参数:\n",
    "#         trainer: GRPOTrainer对象\n",
    "#     返回:\n",
    "#         pd.DataFrame: 包含步骤和对应奖励的数据框\n",
    "#     \"\"\"\n",
    "#     if not hasattr(trainer, 'state') or not hasattr(trainer.state, 'log_history'):\n",
    "#         print(\"训练器没有可用的日志历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbbf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有数据可以绘图!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置Seaborn样式以获得更好看的图表\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "def extract_rewards_from_log(log_path):\n",
    "    \"\"\"从训练日志文件中提取奖励数据\n",
    "    \n",
    "    参数:\n",
    "        log_path: 日志文件路径\n",
    "        \n",
    "    返回:\n",
    "        包含步骤和对应奖励的pandas DataFrame\n",
    "    \"\"\"\n",
    "    # 存储数据的字典\n",
    "    data = defaultdict(list)\n",
    "    step_pattern = re.compile(r'Step\\s+(\\d+)')\n",
    "    reward_pattern = re.compile(r'Reward_(\\d+):\\s+([-\\d.]+)')\n",
    "    mean_reward_pattern = re.compile(r'Mean Reward:\\s+([-\\d.]+)')\n",
    "    \n",
    "    if not os.path.exists(log_path):\n",
    "        print(f\"日志文件 {log_path} 不存在!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # 提取步骤\n",
    "            step_match = step_pattern.search(line)\n",
    "            if step_match:\n",
    "                current_step = int(step_match.group(1))\n",
    "                data['step'].append(current_step)\n",
    "                \n",
    "                # 提取各个奖励函数的值\n",
    "                rewards = reward_pattern.findall(line)\n",
    "                for idx, value in rewards:\n",
    "                    data[f'reward_{idx}'].append(float(value))\n",
    "                \n",
    "                # 提取平均奖励\n",
    "                mean_match = mean_reward_pattern.search(line)\n",
    "                if mean_match:\n",
    "                    data['mean_reward'].append(float(mean_match.group(1)))\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_rewards_from_trainer(trainer):\n",
    "    \"\"\"从trainer对象中直接提取奖励数据\n",
    "    \n",
    "    参数:\n",
    "        trainer: GRPOTrainer对象\n",
    "        \n",
    "    返回:\n",
    "        包含步骤和对应奖励的pandas DataFrame\n",
    "    \"\"\"\n",
    "    if hasattr(trainer, 'state') and hasattr(trainer.state, 'log_history'):\n",
    "        data = defaultdict(list)\n",
    "        for entry in trainer.state.log_history:\n",
    "            if 'step' in entry:\n",
    "                data['step'].append(entry['step'])\n",
    "                \n",
    "                # 提取各个奖励\n",
    "                for key, value in entry.items():\n",
    "                    if key.startswith('reward_'):\n",
    "                        data[key].append(value)\n",
    "                \n",
    "                # 提取平均奖励\n",
    "                if 'mean_reward' in entry:\n",
    "                    data['mean_reward'].append(entry['mean_reward'])\n",
    "                \n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        print(\"训练器没有日志历史或者结构不符合预期!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def plot_rewards(data, title=\"GRPO训练奖励曲线\", save_path=None, moving_avg_window=5):\n",
    "    \"\"\"绘制奖励折线图\n",
    "    \n",
    "    参数:\n",
    "        data: 包含奖励数据的DataFrame\n",
    "        title: 图表标题\n",
    "        save_path: 保存图表的路径，如果为None则显示图表\n",
    "        moving_avg_window: 移动平均窗口大小\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        print(\"没有数据可以绘图!\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # 定义一组专业的颜色\n",
    "    colors = sns.color_palette('viridis', n_colors=len(data.columns)-1)\n",
    "    \n",
    "    # 绘制每个奖励函数的曲线\n",
    "    for i, col in enumerate([col for col in data.columns if col != 'step']):\n",
    "        # 原始数据点（透明度降低）\n",
    "        ax.plot(data['step'], data[col], alpha=0.3, color=colors[i], label=f\"{col} (raw)\")\n",
    "        \n",
    "        # 添加移动平均线\n",
    "        if len(data) >= moving_avg_window:\n",
    "            moving_avg = data[col].rolling(window=moving_avg_window).mean()\n",
    "            ax.plot(data['step'], moving_avg, linewidth=2, color=colors[i], label=f\"{col} ({moving_avg_window}-point avg)\")\n",
    "    \n",
    "    # 添加标题和标签\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Training Steps', fontsize=14)\n",
    "    ax.set_ylabel('Reward', fontsize=14)\n",
    "    \n",
    "    # 添加网格线和图例\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(loc='best', fontsize=12)\n",
    "    \n",
    "    # 添加统计信息\n",
    "    if 'mean_reward' in data.columns:\n",
    "        final_mean = data['mean_reward'].iloc[-1]\n",
    "        max_mean = data['mean_reward'].max()\n",
    "        min_mean = data['mean_reward'].min()\n",
    "        stats_text = f\"Final mean reward: {final_mean:.4f}\\nMax mean reward: {max_mean:.4f}\\nMin mean reward: {min_mean:.4f}\"\n",
    "        plt.figtext(0.02, 0.02, stats_text, fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存或显示图表\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"图表已保存到 {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# 示例用法\n",
    "def visualize_rewards(trainer=None, log_file=None, output_path=None):\n",
    "    \"\"\"可视化训练奖励\n",
    "    \n",
    "    参数:\n",
    "        trainer: GRPOTrainer对象，如果提供则直接从训练器中提取数据\n",
    "        log_file: 日志文件路径，如果trainer不可用则从日志文件中提取数据\n",
    "        output_path: 图表保存路径，默认为当前目录下的'reward_plot.png'\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = 'reward_plot.png'\n",
    "    \n",
    "    if trainer is not None:\n",
    "        data = extract_rewards_from_trainer(trainer)\n",
    "    elif log_file is not None:\n",
    "        data = extract_rewards_from_log(log_file)\n",
    "    else:\n",
    "        print(\"请提供trainer对象或日志文件路径!\")\n",
    "        return\n",
    "    \n",
    "    plot_rewards(data, save_path=output_path)\n",
    "    \n",
    "    # 输出一些统计信息\n",
    "    if not data.empty and 'mean_reward' in data.columns:\n",
    "        print(\"\\n--- 奖励统计信息 ---\")\n",
    "        print(f\"最终平均奖励: {data['mean_reward'].iloc[-1]:.4f}\")\n",
    "        print(f\"最大平均奖励: {data['mean_reward'].max():.4f}\")\n",
    "        print(f\"最小平均奖励: {data['mean_reward'].min():.4f}\")\n",
    "        \n",
    "        # 计算奖励增长率\n",
    "        if len(data) > 1:\n",
    "            first_reward = data['mean_reward'].iloc[0]\n",
    "            last_reward = data['mean_reward'].iloc[-1]\n",
    "            growth = ((last_reward - first_reward) / abs(first_reward)) * 100 if first_reward != 0 else float('inf')\n",
    "            print(f\"奖励增长率: {growth:.2f}%\")\n",
    "\n",
    "# 用法示例\n",
    "# 1. 使用训练器对象\n",
    "# visualize_rewards(trainer=trainer)\n",
    "\n",
    "# 2. 或者使用日志文件\n",
    "visualize_rewards(log_file=\"./outputs_gemma-3_grpo_lora/opt_gemm3_2.log\")\n",
    "\n",
    "# 从训练后直接可视化\n",
    "# 在训练后调用以下代码即可直接可视化\n",
    "# visualize_rewards(trainer=trainer, output_path=\"reward_trends.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95da640",
   "metadata": {},
   "source": [
    "### 模型测试\n",
    "#### 默认模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b72b37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_working_out>\n",
      "Let $N$ be the number of people in the group, so $N = 18$.\n",
      "Each person gets 3 slices of pizza.\n",
      "The total number of slices needed is $18 \\times 3 = 54$ slices.\n",
      "Each pizza has 9 slices.\n",
      "Let $P$ be the number of pizzas they need to order.\n",
      "The total number of slices from $P$ pizzas is $9P$.\n",
      "We need $9P \\ge 54$.\n",
      "Dividing both sides by 9, we get $P \\ge \\frac{54}{9} = 6$.\n",
      "Since they need to order a whole number of pizzas, they need to order at least 6 pizzas.\n",
      "Therefore, they should order 6 pizzas.\n",
      "<end_working_out>\n",
      "<SOLUTION>6\n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\",   \"content\": \"There is a group of 18 people who are ordering pizza. If each person gets 3 slices and each pizza has 9 slices, how many pizzas should they order? \"},\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    tokenize = False,\n",
    ")\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 1024, # Increase for longer outputs!\n",
    "    # Recommended Gemma-3 settings!\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载原始模型（不包含微调）\n",
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "# 定义相同的参数\n",
    "max_seq_length = 1024\n",
    "\n",
    "# 重新加载原始模型（不应用LoRA权重）\n",
    "original_model, original_tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"./models/gemma-3-1b-it\",  # 使用原始模型路径\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = False,\n",
    ")\n",
    "\n",
    "# 测试问题\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},  # 使用之前定义的系统提示词\n",
    "    {\"role\": \"user\", \"content\": \"What is the sqrt of 101?\"},  # 使用同样的测试问题以便比较\n",
    "]\n",
    "\n",
    "# 准备输入\n",
    "test_text = original_tokenizer.apply_chat_template(\n",
    "    test_messages,\n",
    "    add_generation_prompt = True,\n",
    "    tokenize = False,\n",
    ")\n",
    "\n",
    "# 使用TextStreamer直接查看输出\n",
    "from transformers import TextStreamer\n",
    "print(\"\\n原始模型输出：\")\n",
    "_ = original_model.generate(\n",
    "    **original_tokenizer(test_text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 1024,\n",
    "    temperature = 0.8,  # 使用与微调模型相同的温度\n",
    "    top_p = 0.95,\n",
    "    top_k = 64,\n",
    "    streamer = TextStreamer(original_tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426953b",
   "metadata": {},
   "source": [
    "#### finetuning 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfea2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 Lora\n",
    "model.save_lora(\"grpo_saved_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833dc17",
   "metadata": {},
   "source": [
    "#### 保存 Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855619d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma-3/tokenizer_config.json',\n",
       " 'gemma-3/special_tokens_map.json',\n",
       " 'gemma-3/tokenizer.model',\n",
       " 'gemma-3/added_tokens.json',\n",
       " 'gemma-3/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"gemma-3\")  # Local saving\n",
    "tokenizer.save_pretrained(\"gemma-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "790cbde8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:125\u001b[0m, in \u001b[0;36mHfFileSystem._repo_and_revision_exist\u001b[0;34m(self, repo_type, repo_id, revision)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api\u001b[38;5;241m.\u001b[39mrepo_info(\n\u001b[1;32m    126\u001b[0m         repo_id, revision\u001b[38;5;241m=\u001b[39mrevision, repo_type\u001b[38;5;241m=\u001b[39mrepo_type, timeout\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mHF_HUB_ETAG_TIMEOUT\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (RepositoryNotFoundError, HFValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './models'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:545\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mList the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:216\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m repo_and_revision_exist:\n\u001b[0;32m--> 216\u001b[0m         _raise_file_not_found(path, err)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:1136\u001b[0m, in \u001b[0;36m_raise_file_not_found\u001b[0;34m(path, err)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (invalid repository id)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ./models/gemma-3-1b-it (invalid repository id)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \u001b[38;5;66;03m# Change to True to save finetune!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_pretrained_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma-3-finetune\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2357\u001b[0m, in \u001b[0;36munsloth_generic_save_pretrained_merged\u001b[0;34m(self, save_directory, tokenizer, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2355\u001b[0m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2357\u001b[0m unsloth_generic_save(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m   2359\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2304\u001b[0m, in \u001b[0;36munsloth_generic_save\u001b[0;34m(model, tokenizer, save_directory, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, use_temp_dir, commit_message, private, create_pr, revision, commit_description, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munsloth_generic_save\u001b[39m(\n\u001b[1;32m   2276\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     maximum_memory_usage : \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m   2302\u001b[0m ):\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m push_to_hub: token \u001b[38;5;241m=\u001b[39m get_token()\n\u001b[0;32m-> 2304\u001b[0m     merge_and_overwrite_lora(\n\u001b[1;32m   2305\u001b[0m         get_model_name,\n\u001b[1;32m   2306\u001b[0m         model                \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m   2307\u001b[0m         tokenizer            \u001b[38;5;241m=\u001b[39m tokenizer,\n\u001b[1;32m   2308\u001b[0m         save_directory       \u001b[38;5;241m=\u001b[39m save_directory,\n\u001b[1;32m   2309\u001b[0m         push_to_hub          \u001b[38;5;241m=\u001b[39m push_to_hub,\n\u001b[1;32m   2310\u001b[0m         private              \u001b[38;5;241m=\u001b[39m private,\n\u001b[1;32m   2311\u001b[0m         token                \u001b[38;5;241m=\u001b[39m token,\n\u001b[1;32m   2312\u001b[0m         output_dtype         \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2313\u001b[0m         low_disk_space_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2314\u001b[0m         use_temp_file        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2315\u001b[0m     )\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:549\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    547\u001b[0m     original_model_id \u001b[38;5;241m=\u001b[39m get_original_model_id(model_name)\n\u001b[1;32m    548\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m original_model_id\n\u001b[0;32m--> 549\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    551\u001b[0m safetensors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    552\u001b[0m max_size_in_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mls\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, detail: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, refresh: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    List the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m        dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m     path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[1;32m    370\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: detail, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:172\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    169\u001b[0m         revision \u001b[38;5;241m=\u001b[39m revision_in_path\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revision\n\u001b[0;32m--> 172\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# can't list repositories at root\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to repositories lists is not implemented.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/fsspec/spec.py:198\u001b[0m, in \u001b[0;36mAbstractFileSystem._strip_protocol\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    196\u001b[0m protos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m protocol \u001b[38;5;129;01min\u001b[39;00m protos:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    199\u001b[0m         path \u001b[38;5;241m=\u001b[39m path[\u001b[38;5;28mlen\u001b[39m(protocol) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m :]\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "if True: # Change to True to save finetune!\n",
    "    model.save_pretrained_merged(\"gemma-3-finetune\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a0885",
   "metadata": {},
   "source": [
    "### 保存为完整模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27072ac2",
   "metadata": {},
   "source": [
    "##### 保存为 bf16 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4381df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:125\u001b[0m, in \u001b[0;36mHfFileSystem._repo_and_revision_exist\u001b[0;34m(self, repo_type, repo_id, revision)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api\u001b[38;5;241m.\u001b[39mrepo_info(\n\u001b[1;32m    126\u001b[0m         repo_id, revision\u001b[38;5;241m=\u001b[39mrevision, repo_type\u001b[38;5;241m=\u001b[39mrepo_type, timeout\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mHF_HUB_ETAG_TIMEOUT\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (RepositoryNotFoundError, HFValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './models'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:545\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mList the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:216\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m repo_and_revision_exist:\n\u001b[0;32m--> 216\u001b[0m         _raise_file_not_found(path, err)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:1136\u001b[0m, in \u001b[0;36m_raise_file_not_found\u001b[0;34m(path, err)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (invalid repository id)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ./models/gemma-3-1b-it (invalid repository id)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge to 16bit\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: model\u001b[38;5;241m.\u001b[39msave_pretrained_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, save_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_16bit\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: model\u001b[38;5;241m.\u001b[39mpush_to_hub_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf/model\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, save_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_16bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Merge to 4bit\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2357\u001b[0m, in \u001b[0;36munsloth_generic_save_pretrained_merged\u001b[0;34m(self, save_directory, tokenizer, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2355\u001b[0m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2357\u001b[0m unsloth_generic_save(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments)\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m   2359\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/save.py:2304\u001b[0m, in \u001b[0;36munsloth_generic_save\u001b[0;34m(model, tokenizer, save_directory, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, use_temp_dir, commit_message, private, create_pr, revision, commit_description, tags, temporary_location, maximum_memory_usage)\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munsloth_generic_save\u001b[39m(\n\u001b[1;32m   2276\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     maximum_memory_usage : \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m   2302\u001b[0m ):\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m push_to_hub: token \u001b[38;5;241m=\u001b[39m get_token()\n\u001b[0;32m-> 2304\u001b[0m     merge_and_overwrite_lora(\n\u001b[1;32m   2305\u001b[0m         get_model_name,\n\u001b[1;32m   2306\u001b[0m         model                \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m   2307\u001b[0m         tokenizer            \u001b[38;5;241m=\u001b[39m tokenizer,\n\u001b[1;32m   2308\u001b[0m         save_directory       \u001b[38;5;241m=\u001b[39m save_directory,\n\u001b[1;32m   2309\u001b[0m         push_to_hub          \u001b[38;5;241m=\u001b[39m push_to_hub,\n\u001b[1;32m   2310\u001b[0m         private              \u001b[38;5;241m=\u001b[39m private,\n\u001b[1;32m   2311\u001b[0m         token                \u001b[38;5;241m=\u001b[39m token,\n\u001b[1;32m   2312\u001b[0m         output_dtype         \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2313\u001b[0m         low_disk_space_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2314\u001b[0m         use_temp_file        \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2315\u001b[0m     )\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:549\u001b[0m, in \u001b[0;36mmerge_and_overwrite_lora\u001b[0;34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[0m\n\u001b[1;32m    547\u001b[0m     original_model_id \u001b[38;5;241m=\u001b[39m get_original_model_id(model_name)\n\u001b[1;32m    548\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m original_model_id\n\u001b[0;32m--> 549\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m HfFileSystem(token \u001b[38;5;241m=\u001b[39m token)\u001b[38;5;241m.\u001b[39mls(model_name, detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    551\u001b[0m safetensors_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    552\u001b[0m max_size_in_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:368\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mls\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, detail: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, refresh: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    341\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    List the contents of a directory.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m        dictionaries (if detail=True).\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    369\u001b[0m     path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[1;32m    370\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: detail, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:172\u001b[0m, in \u001b[0;36mHfFileSystem.resolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    169\u001b[0m         revision \u001b[38;5;241m=\u001b[39m revision_in_path\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revision\n\u001b[0;32m--> 172\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# can't list repositories at root\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to repositories lists is not implemented.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/unsloth/lib/python3.11/site-packages/fsspec/spec.py:198\u001b[0m, in \u001b[0;36mAbstractFileSystem._strip_protocol\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    196\u001b[0m protos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m protocol \u001b[38;5;129;01min\u001b[39;00m protos:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    199\u001b[0m         path \u001b[38;5;241m=\u001b[39m path[\u001b[38;5;28mlen\u001b[39m(protocol) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m :]\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(protocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "# Merge to 16bit\n",
    "if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "if True: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# Merge to 4bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# Just LoRA adapters\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Change to True to upload finetune\n",
    "    model.push_to_hub_merged(\n",
    "        \"HF_ACCOUNT/gemma-3-finetune\", tokenizer,\n",
    "        token = \"hf_...\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为 GGUF 格式\n",
    "# if False:\n",
    "#     model.save_pretrained_gguf(\n",
    "#         \"gemma-3-finetune\",\n",
    "#         quantization_type = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a89623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False: # Change to True to upload GGUF\n",
    "#     model.push_to_hub_gguf(\n",
    "#         \"gemma-3-finetune\",\n",
    "#         quantization_type = \"Q8_0\", # Only Q8_0, BF16, F16 supported\n",
    "#         repo_id = \"HF_ACCOUNT/gemma-finetune-gguf\",\n",
    "#         token = \"hf_...\",\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
